{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "# The GPU id to use, usually either \"0\" or \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1,2,3\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from os.path import abspath, expanduser\n",
    "sys.path.append(abspath(expanduser(\"/../..\")))\n",
    "import unittest\n",
    "from sequence_annotation.processor.compiler import SimpleCompiler,AnnSeqCompiler\n",
    "from sequence_annotation.model.model_processor import SimpleModel,ModelCreator,IModelProcessor\n",
    "from sequence_annotation.processor.data_processor import AnnSeqData,SimpleData\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation,Input\n",
    "from sequence_annotation.worker.train_worker import TrainWorker\n",
    "from sequence_annotation.worker.test_worker import TestWorker\n",
    "from sequence_annotation.pipeline.pipeline import Pipeline\n",
    "from sequence_annotation.model.customize import MaskedConvolution1D,RemoveMask\n",
    "\n",
    "from sequence_annotation.genome_handler.seq_container import AnnSeqContainer\n",
    "from sequence_annotation.genome_handler.ann_seq_processor import class_count\n",
    "from sequence_annotation.data_handler.fasta import read_fasta\n",
    "from sequence_annotation.data_handler.json import read_json\n",
    "from sequence_annotation.data_handler.seq_converter import SeqConverter\n",
    "from sequence_annotation.pipeline.wrapper import fit_generator_wrapper_generator\n",
    "from sequence_annotation.pipeline.wrapper import evaluate_generator_wrapper_generator\n",
    "from sequence_annotation.pipeline.callback import AdvancedModelCheckpoint,ResultHistory,ModelPlot\n",
    "from sequence_annotation.processor.metric import BatchCount,TruePositive,SampleCount\n",
    "from sequence_annotation.processor.stateful_metric import StatefulMetric\n",
    "from keras.callbacks import TensorBoard \n",
    "import numpy as np\n",
    "from keras.utils import plot_model\n",
    "from keras.callbacks import EarlyStopping\n",
    "#from hyperas import optim\n",
    "#from hyperas.distributions import choice, uniform\n",
    "#from hyperopt import Trials, STATUS_OK, tpe\n",
    "import random\n",
    "from sequence_annotation.genome_handler.sequence import AnnSequence\n",
    "from sequence_annotation.genome_handler.seq_container import AnnSeqContainer\n",
    "from sequence_annotation.pipeline.data_generator import DataGenerator\n",
    "#from hyperopt import Trials, STATUS_OK, tpe,fmin, tpe,hp\n",
    "from keras.layers import BatchNormalization, ReLU, Conv1D, Add, Dropout, Concatenate,Layer,LSTM,Bidirectional,RNN,Masking,SimpleRNNCell\n",
    "from keras.engine.training import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasta = read_fasta('../io/data/2018_11_24/Araport11_exon_2018_11_24_merged_with_coordinate_file_megred_exon_dist_to_five_1000_dist_to_three_500_merged.fasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deepdish as dd\n",
    "h5=dd.io.load('../io/data/2018_11_24/Araport11_exon_2018_11_24_merged_with_coordinate_file_megred_exon_dist_to_five_1000_dist_to_three_500_merged.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_seqs = AnnSeqContainer().from_dict(h5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Activation\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "import keras\n",
    "\n",
    "\n",
    "from keras.utils.generic_utils import CustomObjectScope\n",
    "from keras.utils import multi_gpu_model\n",
    "class SeqAnnModelBuilder(IModelProcessor):\n",
    "    def __init__(self,setting,input_dim,output_dim):\n",
    "        self._record = {'setting':setting,\n",
    "                        'input_dim':input_dim,\n",
    "                        'output_dim':output_dim}\n",
    "        self._setting = setting\n",
    "        self._input_dim = input_dim\n",
    "        self._output_dim = output_dim\n",
    "    def process(self):\n",
    "        model = Sequential()\n",
    "        inputs = Input(shape=(None,self._input_dim),name='Input')\n",
    "        inputs_ = Masking(mask_value=0,name='mask')(inputs)\n",
    "        previous_layer = inputs_\n",
    "        previous_input = inputs_\n",
    "        cnn_number = 16\n",
    "        rnn_number = 8\n",
    "        for index in range(cnn_number):\n",
    "            if previous_layer!=previous_input:\n",
    "                input_ = Concatenate(name='CNN_concat_'+str(index))([previous_input,previous_layer])\n",
    "            else:\n",
    "                input_ = previous_input\n",
    "            cnn = MaskedConvolution1D(2,kernel_size=32,activation='relu',padding='same',name='cnn_'+str(index))(input_)\n",
    "            bn = BatchNormalization()(cnn)\n",
    "            previous_input = input_\n",
    "            previous_layer = bn\n",
    "        for index in range(rnn_number):\n",
    "            if previous_layer!=previous_input:\n",
    "                input_ = Concatenate(name='RNN_concat_'+str(index))([previous_input,previous_layer])\n",
    "            else:\n",
    "                input_ = previous_input\n",
    "            with CustomObjectScope({'IRNNCell' : IRNNCell}):\n",
    "                cnn_input = MaskedConvolution1D(8,kernel_size=1,activation=None,padding='same',name='rnn_cnn_'+str(index))(input_)\n",
    "                rnn_ = RNN(IRNNCell(8), return_sequences=True,name='rnn_'+str(index))\n",
    "                rnn = Bidirectional(rnn_,name='bidir_rnn_'+str(index))(cnn_input)\n",
    "                bn = BatchNormalization()(rnn)\n",
    "                previous_input = input_\n",
    "                previous_layer = bn\n",
    "        cnn = MaskedConvolution1D(self._output_dim,kernel_size=1,activation='softmax',name='predict',padding='same')(previous_layer)\n",
    "        outputs = RemoveMask()(cnn)\n",
    "        self._model = Model(inputs=inputs, outputs=outputs)\n",
    "    @property\n",
    "    def model(self):\n",
    "        return self._model\n",
    "    @property\n",
    "    def record(self):\n",
    "        return self._record\n",
    "class IRNNCell(Layer):\n",
    "    def __init__(self, units, **kwargs):\n",
    "        self.units = units\n",
    "        self.state_size = units\n",
    "        super().__init__(**kwargs)\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config['units'] = self.units\n",
    "        return config\n",
    "    def build(self, input_shape):\n",
    "        self.activation =  Activation('relu')\n",
    "        self.built = True\n",
    "    def call(self, inputs, states):\n",
    "        prev_output = states[0]\n",
    "        output = self.activation(inputs + prev_output)\n",
    "        return output, [output]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "if hasattr(config,\"gpu_options\"):\n",
    "    config.gpu_options.allow_growth=True\n",
    "sess = tf.Session(config=config)\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import median\n",
    "median_len = median([len(seq) for seq in ann_seqs])\n",
    "median_seqs = AnnSeqContainer()\n",
    "median_seqs.ANN_TYPES = ann_seqs.ANN_TYPES\n",
    "median_fasta = {}\n",
    "number = 0\n",
    "for seq in ann_seqs:\n",
    "    if len(seq) < median_len:\n",
    "        median_seqs.add(seq)\n",
    "        median_fasta[seq.id]=fasta[seq.id]\n",
    "        number += 1\n",
    "    if number >= 100:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing model..\n",
      "Processing data...\n",
      "Compiling model...\n",
      "Processing worker...\n",
      "Executing...\n",
      "Start working(2018-12-04 16:32:00)\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 34s 34s/step - loss: 1.4203 - mix_FP: 89994.0000 - mix_FN: 620.0000 - intron_FN: 27991.0000 - intron_TN: 203158.0000 - other_TP: 45664.0000 - other_TN: 104414.0000 - other_FN: 104336.0000 - intron_TP: 4286.0000 - exon_FP: 37907.0000 - exon_TP: 23015.0000 - intron_FP: 52482.0000 - other_FP: 33503.0000 - mix_TN: 196237.0000 - exon_TN: 146056.0000 - mix_TP: 1066.0000 - exon_FN: 80939.0000\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 22s 22s/step - loss: 1.3882 - mix_FP: 90047.0000 - mix_FN: 769.0000 - intron_FN: 29058.0000 - intron_TN: 210956.0000 - other_TP: 54544.0000 - other_TN: 107310.0000 - other_FN: 95456.0000 - intron_TP: 3219.0000 - exon_FP: 37077.0000 - exon_TP: 26822.0000 - intron_FP: 44684.0000 - other_FP: 30607.0000 - mix_TN: 196184.0000 - exon_TN: 146886.0000 - mix_TP: 917.0000 - exon_FN: 77132.0000\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 22s 22s/step - loss: 1.3124 - mix_FP: 91568.0000 - mix_FN: 1252.0000 - intron_FN: 28630.0000 - intron_TN: 217628.0000 - other_TP: 53340.0000 - other_TN: 108443.0000 - other_FN: 96660.0000 - intron_TP: 3647.0000 - exon_FP: 43754.0000 - exon_TP: 27688.0000 - intron_FP: 38012.0000 - other_FP: 29474.0000 - mix_TN: 194663.0000 - exon_TN: 140209.0000 - mix_TP: 434.0000 - exon_FN: 76266.0000\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 23s 23s/step - loss: 1.2502 - mix_FP: 88029.0000 - mix_FN: 1252.0000 - intron_FN: 28234.0000 - intron_TN: 218787.0000 - other_TP: 57984.0000 - other_TN: 107061.0000 - other_FN: 92016.0000 - intron_TP: 4043.0000 - exon_FP: 41072.0000 - exon_TP: 28646.0000 - intron_FP: 36853.0000 - other_FP: 30856.0000 - mix_TN: 198202.0000 - exon_TN: 142891.0000 - mix_TP: 434.0000 - exon_FN: 75308.0000\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 23s 23s/step - loss: 1.1948 - mix_FP: 81689.0000 - mix_FN: 1255.0000 - intron_FN: 28101.0000 - intron_TN: 219304.0000 - other_TP: 62734.0000 - other_TN: 109982.0000 - other_FN: 87266.0000 - intron_TP: 4176.0000 - exon_FP: 41567.0000 - exon_TP: 33049.0000 - intron_FP: 36336.0000 - other_FP: 27935.0000 - mix_TN: 204542.0000 - exon_TN: 142396.0000 - mix_TP: 431.0000 - exon_FN: 70905.0000\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 23s 23s/step - loss: 1.1552 - mix_FP: 75605.0000 - mix_FN: 1266.0000 - intron_FN: 26901.0000 - intron_TN: 222693.0000 - other_TP: 70348.0000 - other_TN: 109882.0000 - other_FN: 79652.0000 - intron_TP: 5376.0000 - exon_FP: 38820.0000 - exon_TP: 36366.0000 - intron_FP: 32947.0000 - other_FP: 28035.0000 - mix_TN: 210626.0000 - exon_TN: 145143.0000 - mix_TP: 420.0000 - exon_FN: 67588.0000\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 22s 22s/step - loss: 1.1194 - mix_FP: 70701.0000 - mix_FN: 790.0000 - intron_FN: 26540.0000 - intron_TN: 225118.0000 - other_TP: 74750.0000 - other_TN: 106448.0000 - other_FN: 75250.0000 - intron_TP: 5737.0000 - exon_FP: 37152.0000 - exon_TP: 36690.0000 - intron_FP: 30522.0000 - other_FP: 31469.0000 - mix_TN: 215530.0000 - exon_TN: 146811.0000 - mix_TP: 896.0000 - exon_FN: 67264.0000\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 23s 23s/step - loss: 1.0946 - mix_FP: 66715.0000 - mix_FN: 828.0000 - intron_FN: 26830.0000 - intron_TN: 227134.0000 - other_TP: 78917.0000 - other_TN: 105753.0000 - other_FN: 71083.0000 - intron_TP: 5447.0000 - exon_FP: 37267.0000 - exon_TP: 38043.0000 - intron_FP: 28506.0000 - other_FP: 32164.0000 - mix_TN: 219516.0000 - exon_TN: 146696.0000 - mix_TP: 858.0000 - exon_FN: 65911.0000\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 23s 23s/step - loss: 1.0701 - mix_FP: 65168.0000 - mix_FN: 897.0000 - intron_FN: 25063.0000 - intron_TN: 224145.0000 - other_TP: 79324.0000 - other_TN: 106102.0000 - other_FN: 70676.0000 - intron_TP: 7214.0000 - exon_FP: 34981.0000 - exon_TP: 37131.0000 - intron_FP: 31495.0000 - other_FP: 31815.0000 - mix_TN: 221063.0000 - exon_TN: 148982.0000 - mix_TP: 789.0000 - exon_FN: 66823.0000\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 23s 23s/step - loss: 1.0424 - mix_FP: 57030.0000 - mix_FN: 1061.0000 - intron_FN: 25129.0000 - intron_TN: 226150.0000 - other_TP: 83221.0000 - other_TN: 105956.0000 - other_FN: 66779.0000 - intron_TP: 7148.0000 - exon_FP: 38021.0000 - exon_TP: 40421.0000 - intron_FP: 29490.0000 - other_FP: 31961.0000 - mix_TN: 229201.0000 - exon_TN: 145942.0000 - mix_TP: 625.0000 - exon_FN: 63533.0000\n",
      "End working(2018-12-04 16:36:46)\n",
      "Spend time: 00:04:45\n"
     ]
    }
   ],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "builder = SeqAnnModelBuilder({},4,4)\n",
    "compiler = AnnSeqCompiler('adam','categorical_crossentropy',\n",
    "                          ann_types=median_seqs.ANN_TYPES,values_to_ignore=0)\n",
    "data = AnnSeqData({'data':{'training':{'inputs':median_fasta,\n",
    "                                       'answers':median_seqs}\n",
    "                          },'ANN_TYPES':median_seqs.ANN_TYPES},\n",
    "                  discard_invalid_seq=False,validation_split=0,\n",
    "                  do_validate=True,padding_value=0\n",
    "              \n",
    "                 )\n",
    "worker = TrainWorker(is_verbose_visible=True)\n",
    "callbacks = [ModelPlot('2018_11_29/model.png',\n",
    "                        show_shapes =True,\n",
    "                        show_layer_names =True),\n",
    "             TensorBoard('../io/logs/',write_graph=True, write_grads=True, write_images=True),\n",
    "             ResultHistory('2018_11_29/result.csv',period=3,verbose=True),\n",
    "             AdvancedModelCheckpoint('2018_11_29/weights/weights_{epoch:03d}.hdf5',period=1)]\n",
    "wrapper = fit_generator_wrapper_generator(verbose=1,batch_size=100,\n",
    "                                          epochs=10,epoch_shuffle=True,callbacks=[])\n",
    "pipeline = Pipeline(builder,data,compiler,worker,\n",
    "                    wrapper,is_prompt_visible=True)\n",
    "\n",
    "pipeline.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelOptimizer:\n",
    "    def __init__(self):\n",
    "        self.x_train, self.y_train, self.x_test, self.y_test=self._prepare_data()\n",
    "    def _prepare_data(self):\n",
    "        x,y=generator()\n",
    "        val_x,val_y=generator()\n",
    "        data = SimpleData({'training':{'inputs':x,'answers':y},\n",
    "                           'validation':{'inputs':val_x,'answers':val_y}})\n",
    "        data.before_process()\n",
    "        data.process()\n",
    "        data.after_process()\n",
    "        return (data.data['training']['inputs'],\n",
    "                data.data['training']['answers'],\n",
    "                data.data['validation']['inputs'],\n",
    "                data.data['validation']['answers'])\n",
    "    def _create_model(self,space):\n",
    "        builder = SeqAnnModelBuilder({},3,4)\n",
    "        builder.process()\n",
    "        simple_model = SimpleModel(builder.model)\n",
    "        return simple_model\n",
    "    def get_loss(self,space):\n",
    "        model = self._create_model(space)\n",
    "        compiler = AnnSeqCompiler('adam','categorical_crossentropy')\n",
    "        data = SimpleData({'training':{'inputs':self.x_train,'answers':self.y_train},\n",
    "                          'validation':{'inputs':self.x_test,'answers':self.y_test}})\n",
    "        worker = TrainWorker(is_verbose_visible=False)\n",
    "        wrapper = fit_generator_wrapper_generator(verbose=1,batch_size=1000,\n",
    "                                                  epochs=30,callbacks=[#ModelPlot(str(space['layer'])+'.png',show_shapes =True,\n",
    "                                                                        #          show_layer_names =True),\n",
    "                                                                        #ResultHistory(str(space['layer'])+'tsv',period=2,verbose=True),\n",
    "                                                                        #AdvancedModelCheckpoint('weights.{epoch:02d}.hdf5',period=2),\n",
    "                                                  #                      EarlyStopping(patience=5)\n",
    "                                                  ])\n",
    "        pipeline = Pipeline(model,data,compiler,worker,\n",
    "                            wrapper,is_prompt_visible=False)\n",
    "\n",
    "        pipeline.execute()\n",
    "        #get the highest validation accuracy of the training epochs\n",
    "        val_loss = np.amax(worker.result['loss']) \n",
    "        #self._loss = -validation_acc\n",
    "        print('Best validation loss of epoch:', val_loss)\n",
    "        return {'loss': val_loss, 'status': STATUS_OK, 'model': model.model,'space':space}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelOptimizer = ModelOptimizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = Trials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = fmin(modelOptimizer.get_loss, space={'layer':hp.choice('nubmer',[_ for _ in range(1,11)])}\n",
    "           , algo=tpe.suggest ,trials=trials, max_evals=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
