{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "# The GPU id to use, usually either \"0\" or \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from os.path import abspath, expanduser\n",
    "sys.path.append(abspath(expanduser(\"/../..\")))\n",
    "import unittest\n",
    "from sequence_annotation.processor.compiler.keras import SimpleCompiler,AnnSeqCompiler\n",
    "from sequence_annotation.model.model_processor import SimpleModel,ModelCreator,IModelProcessor\n",
    "from sequence_annotation.processor.data_processor import AnnSeqData,SimpleData\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation,Input\n",
    "from sequence_annotation.processor.worker.train_worker import TrainWorker\n",
    "from sequence_annotation.processor.worker.test_worker import TestWorker\n",
    "from sequence_annotation.pipeline.pipeline import Pipeline\n",
    "from sequence_annotation.model.customize import MaskedConvolution1D,RemoveMask,noised_relu\n",
    "from sequence_annotation.genome_handler.seq_container import AnnSeqContainer\n",
    "from sequence_annotation.genome_handler.ann_seq_processor import class_count\n",
    "from sequence_annotation.data_handler.fasta import read_fasta\n",
    "from sequence_annotation.data_handler.json import read_json\n",
    "from sequence_annotation.data_handler.seq_converter import SeqConverter\n",
    "from sequence_annotation.pipeline.wrapper import fit_generator_wrapper_generator,fit_wrapper_generator\n",
    "from sequence_annotation.pipeline.wrapper import evaluate_generator_wrapper_generator\n",
    "from sequence_annotation.pipeline.callback import AdvancedModelCheckpoint,ResultHistory,ModelPlot\n",
    "from sequence_annotation.processor.metric.metric import BatchCount,TruePositive,SampleCount,Accuracy\n",
    "from sequence_annotation.processor.metric.metric_builder import MetricBuilder\n",
    "from sequence_annotation.processor.metric.stateful_metric import StatefulMetric\n",
    "from keras.callbacks import TensorBoard \n",
    "import numpy as np\n",
    "from keras.utils import plot_model\n",
    "from keras.callbacks import EarlyStopping\n",
    "from hyperopt import Trials, STATUS_OK, tpe\n",
    "import random\n",
    "from sequence_annotation.genome_handler.sequence import AnnSequence\n",
    "from sequence_annotation.genome_handler.seq_container import AnnSeqContainer\n",
    "from sequence_annotation.pipeline.data_generator import DataGenerator\n",
    "from keras.layers import BatchNormalization, ReLU, Conv1D, Add, Dropout, Concatenate,Layer,LSTM,Bidirectional\n",
    "from keras.layers import RNN,Masking,SimpleRNNCell,CuDNNGRU\n",
    "from tensorflow.contrib.cudnn_rnn import CudnnCompatibleGRUCell\n",
    "from keras.engine.training import Model\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "config = tf.ConfigProto()\n",
    "if hasattr(config,\"gpu_options\"):\n",
    "    config.gpu_options.allow_growth=True\n",
    "sess = tf.Session(config=config)\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deepdish as dd\n",
    "h5=dd.io.load('../io/data/2018_11_24/Araport11_exon_2018_11_24_merged_with_coordinate_file_megred_exon_dist_to_five_1000_dist_to_three_500_merged.h5')\n",
    "fasta = read_fasta('../io/data/2018_11_24/Araport11_exon_2018_11_24_merged_with_coordinate_file_megred_exon_dist_to_five_1000_dist_to_three_500_merged.fasta')\n",
    "ann_seqs = AnnSeqContainer().from_dict(h5)\n",
    "from numpy import median\n",
    "median_len = median([len(seq) for seq in ann_seqs])\n",
    "median_fasta = {}\n",
    "for seq in ann_seqs:\n",
    "    if len(seq)<= median_len:\n",
    "        median_fasta[seq.id]=fasta[seq.id]\n",
    "keys = list(median_fasta.keys())\n",
    "random.shuffle(keys)\n",
    "selected_seqs = AnnSeqContainer()\n",
    "selected_seqs.ANN_TYPES = ann_seqs.ANN_TYPES\n",
    "selected_fasta = {}\n",
    "number = 0\n",
    "for seq_id in keys:\n",
    "    selected_seqs.add(ann_seqs.get(seq_id))\n",
    "    selected_fasta[seq_id]=median_fasta[seq_id]\n",
    "    number += 1\n",
    "    if number >= int(10):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IRNNCell(Layer):\n",
    "    def __init__(self, units,relu_noise_cooef, **kwargs):\n",
    "        self.units = units\n",
    "        self.state_size = units\n",
    "        self._relu_noise_cooef = relu_noise_cooef\n",
    "        super().__init__(**kwargs)\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config['units'] = self.units\n",
    "        config['relu_noise_cooef']= self._relu_noise_cooef\n",
    "        return config\n",
    "    def build(self, input_shape):\n",
    "        self.kernel = self.add_weight(shape=(input_shape[-1], self.units),\n",
    "                                      initializer='random_uniform',\n",
    "                                      name='kernel')\n",
    "        self.bias = self.add_weight(shape=(1,self.units),\n",
    "                                      initializer='zeros',\n",
    "                                      name='bias')\n",
    "        self.activation =  noised_relu\n",
    "        self.built = True\n",
    "    def call(self, inputs, states):\n",
    "        prev_output = states[0]\n",
    "        inputs_ = K.dot(inputs, self.kernel)\n",
    "        output = self.activation(inputs_ + prev_output+self.bias,c=self._relu_noise_cooef)\n",
    "        return output, [output]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Activation\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "import keras\n",
    "from keras.utils.generic_utils import CustomObjectScope\n",
    "from keras.utils import multi_gpu_model\n",
    "\n",
    "class SeqAnnModelBuilder(IModelProcessor):\n",
    "    def __init__(self,input_dim,output_dim,cnn_kernel_size=2,cnn_unit=2,cnn_layer=2,\n",
    "                 rnn_unit=2,rnn_layer=2,softmax_unit=2,relu_noise_cooef=0):\n",
    "        self._record = {'input_dim':input_dim,\n",
    "                        'output_dim':output_dim,\n",
    "                        'cnn_kernel_size':cnn_kernel_size,\n",
    "                        'cnn_unit':cnn_unit,\n",
    "                        'cnn_layer':cnn_layer,\n",
    "                        'rnn_unit':rnn_unit,\n",
    "                        'rnn_layer':rnn_layer,\n",
    "                        'softmax_unit':softmax_unit,\n",
    "                        'relu_noise_cooef':relu_noise_cooef}\n",
    "    def process(self):\n",
    "        input_dim = self._record['input_dim']\n",
    "        output_dim = self._record['output_dim']\n",
    "        inputs = Input(shape=(None,input_dim),name='Input')\n",
    "        inputs_ = Masking(mask_value=0,name='mask')(inputs)\n",
    "        previous_layer = inputs_\n",
    "        previous_input = inputs_\n",
    "        cnn_number = self._record['cnn_layer']\n",
    "        rnn_number = self._record['rnn_layer']\n",
    "        cnn_kernel_size = self._record['cnn_kernel_size']\n",
    "        cnn_unit = self._record['cnn_unit']\n",
    "        rnn_unit = self._record['rnn_unit']\n",
    "        softmax_unit = self._record['softmax_unit']\n",
    "        relu_noise_cooef = self._record['relu_noise_cooef']\n",
    "        for index in range(cnn_number):\n",
    "            if previous_layer!=previous_input:\n",
    "                input_ = Concatenate(name='CNN_concat_'+str(index))([previous_input,previous_layer])\n",
    "            else:\n",
    "                input_ = previous_input\n",
    "            cnn = MaskedConvolution1D(cnn_unit,kernel_size=cnn_kernel_size,\n",
    "                                      activation='relu',padding='same',\n",
    "                                      name='cnn_'+str(index))(input_)\n",
    "            bn = BatchNormalization()(cnn)\n",
    "            previous_input = input_\n",
    "            previous_layer = bn\n",
    "        if softmax_unit is not None:\n",
    "            softmax = MaskedConvolution1D(softmax_unit,kernel_size=1,\n",
    "                                          activation='softmax',padding='same',\n",
    "                                          name='softmax')(previous_input)\n",
    "        \n",
    "            previous_input = softmax\n",
    "            previous_layer = softmax\n",
    "        for index in range(rnn_number):\n",
    "            if previous_layer!=previous_input:\n",
    "                input_ = Concatenate(name='RNN_concat_'+str(index))([previous_input,previous_layer])\n",
    "            else:\n",
    "                input_ = previous_input\n",
    "            with CustomObjectScope({'IRNNCell' : IRNNCell}):\n",
    "                rnn_ = RNN(IRNNCell(rnn_unit,relu_noise_cooef=relu_noise_cooef),\n",
    "                           return_sequences=True,name='rnn_'+str(index))\n",
    "                rnn = Bidirectional(rnn_,name='bidir_rnn_'+str(index))(input_)\n",
    "                if index < (rnn_number-1):\n",
    "                    bn = BatchNormalization()(rnn)\n",
    "                    previous_layer = bn\n",
    "                else:\n",
    "                    previous_layer = rnn\n",
    "                previous_input = input_\n",
    "        cnn = MaskedConvolution1D(output_dim,kernel_size=1,activation='softmax',\n",
    "                                  name='predict',padding='same')(previous_layer)\n",
    "        outputs = RemoveMask()(cnn)\n",
    "        self._model = Model(inputs=inputs, outputs=outputs)\n",
    "    @property\n",
    "    def model(self):\n",
    "        return self._model\n",
    "    @property\n",
    "    def record(self):\n",
    "        return self._record\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelOptimizer:\n",
    "    def __init__(self):\n",
    "        self.x_train, self.y_train, self.x_test, self.y_test=self._prepare_data()\n",
    "        self.record = []\n",
    "        self._id=1\n",
    "    def _prepare_data(self):\n",
    "        data = AnnSeqData({'data':{'training':{'inputs':selected_fasta,\n",
    "                                               'answers':selected_seqs}\n",
    "                                  },'ANN_TYPES':selected_seqs.ANN_TYPES},\n",
    "                          discard_invalid_seq=True,validation_split=0.5,\n",
    "                          do_validate=True,padding_value=0\n",
    "\n",
    "                         )\n",
    "        data.before_process()\n",
    "        data.process()\n",
    "        data.after_process()\n",
    "        return (data.data['training']['inputs'],\n",
    "                data.data['training']['answers'],\n",
    "                data.data['validation']['inputs'],\n",
    "                data.data['validation']['answers'])\n",
    "    def _create_model(self,space):\n",
    "        builder = SeqAnnModelBuilder(**space)\n",
    "        builder.process()\n",
    "        simple_model = SimpleModel(builder.model)\n",
    "        return simple_model\n",
    "    def get_loss(self,space):\n",
    "        print(space)\n",
    "        model = self._create_model(space)\n",
    "        compiler = SimpleCompiler('adam','categorical_crossentropy',metrics=[Accuracy(values_to_ignore=0)])\n",
    "        data = SimpleData({'training':{'inputs':self.x_train,'answers':self.y_train},\n",
    "                          'validation':{'inputs':self.x_test,'answers':self.y_test}})\n",
    "        worker = TrainWorker(is_verbose_visible=True)\n",
    "        callbacks = [ModelPlot('2018_12_09/model_'+str(self._id)+'.png',\n",
    "                        show_shapes =True,\n",
    "                        show_layer_names =True),\n",
    "                     ResultHistory('2018_12_09/result_'+str(self._id)+'.csv',period=1,verbose=True)]\n",
    "        wrapper = fit_generator_wrapper_generator(verbose=1,batch_size=40,epochs=25,\n",
    "                                                 callbacks=callbacks)\n",
    "        pipeline = Pipeline(model,data,compiler,worker,\n",
    "                            wrapper,is_prompt_visible=True)\n",
    "\n",
    "        pipeline.execute()\n",
    "        #get the highest validation accuracy of the training epochs\n",
    "        val_acc = np.amax(worker.result['val_categorical_accuracy']) \n",
    "        #self._loss = -validation_acc\n",
    "        self._id += 1\n",
    "        print('Best validation accuracy of epoch:', val_acc)\n",
    "        self.record.append({'metric':worker.result,'space':space})\n",
    "        return {'loss': -val_acc, 'status': STATUS_OK,'space':space}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelOptimizer2 = ModelOptimizer()\n",
    "trials2 = Trials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from hyperopt import Trials, STATUS_OK, tpe,fmin, tpe,hp\n",
    "import pickle\n",
    "space2 = {'input_dim':4,\n",
    "         'output_dim':4, \n",
    "         'cnn_kernel_size':120, \n",
    "         'cnn_unit':4,#hp.randint('cnn_unit',4)+1, \n",
    "         'cnn_layer':8,#hp.randint('cnn_layer',33), \n",
    "         'rnn_unit':110,\n",
    "         'rnn_layer':4,\n",
    "         'relu_noise_cooef':0#hp.uniform('relu_noise_cooef',0,1)\n",
    "         }\n",
    "#best = fmin(modelOptimizer2.get_loss, space=space2,algo=tpe.suggest ,trials=trials2, max_evals=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rnn_unit': 107}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(trials2, open(\"2018_12_09/trails.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f815c4dfc18>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as pyplt\n",
    "pyplt.scatter([r['space']['rnn_unit'] for r in trials2.results],\n",
    "              [-r['loss'] for r in trials2.results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data...\n",
      "Processing model..\n",
      "Compiling model...\n",
      "Processing worker...\n",
      "Executing...\n",
      "Start working(2018-12-15 09:15:52)\n",
      "Epoch 1/1000\n",
      "1/1 [==============================] - 0s 371ms/step - loss: 1.5048 - acc: 0.1650 - exon_FN: 4205.0000 - mix_FN: 0.0000e+00 - intron_FN: 915.0000 - exon_TP: 1215.0000 - intron_FP: 6306.0000 - categorical_accuracy: 0.1650 - intron_TP: 1279.0000 - other_TN: 7614.0000 - other_TP: 0.0000e+00 - other_FP: 0.0000e+00 - mix_TN: 10445.0000 - exon_TN: 8049.0000 - mix_FP: 4669.0000 - exon_FP: 1645.0000 - mix_TP: 0.0000e+00 - other_FN: 7500.0000 - intron_TN: 6614.0000 - val_loss: 1.4964 - val_acc: 0.1230 - val_exon_FN: 2576.0000 - val_mix_FN: 0.0000e+00 - val_intron_FN: 696.0000 - val_exon_TP: 718.0000 - val_intron_FP: 5345.0000 - val_categorical_accuracy: 0.1230 - val_intron_TP: 793.0000 - val_other_TN: 4783.0000 - val_other_TP: 0.0000e+00 - val_other_FP: 0.0000e+00 - val_mix_TN: 8375.0000 - val_exon_TN: 7470.0000 - val_mix_FP: 3908.0000 - val_exon_FP: 1519.0000 - val_mix_TP: 0.0000e+00 - val_other_FN: 7500.0000 - val_intron_TN: 5449.0000\n",
      "Epoch 2/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.4922 - acc: 0.1650 - exon_FN: 4205.0000 - mix_FN: 0.0000e+00 - intron_FN: 915.0000 - exon_TP: 1215.0000 - intron_FP: 6306.0000 - categorical_accuracy: 0.1650 - intron_TP: 1279.0000 - other_TN: 7614.0000 - other_TP: 0.0000e+00 - other_FP: 0.0000e+00 - mix_TN: 10445.0000 - exon_TN: 8049.0000 - mix_FP: 4669.0000 - exon_FP: 1645.0000 - mix_TP: 0.0000e+00 - other_FN: 7500.0000 - intron_TN: 6614.0000 - val_loss: 1.4810 - val_acc: 0.1230 - val_exon_FN: 2576.0000 - val_mix_FN: 0.0000e+00 - val_intron_FN: 696.0000 - val_exon_TP: 718.0000 - val_intron_FP: 5345.0000 - val_categorical_accuracy: 0.1230 - val_intron_TP: 793.0000 - val_other_TN: 4783.0000 - val_other_TP: 0.0000e+00 - val_other_FP: 0.0000e+00 - val_mix_TN: 8375.0000 - val_exon_TN: 7470.0000 - val_mix_FP: 3908.0000 - val_exon_FP: 1519.0000 - val_mix_TP: 0.0000e+00 - val_other_FN: 7500.0000 - val_intron_TN: 5449.0000\n",
      "Epoch 3/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.4780 - acc: 0.1650 - exon_FN: 4205.0000 - mix_FN: 0.0000e+00 - intron_FN: 915.0000 - exon_TP: 1215.0000 - intron_FP: 6306.0000 - categorical_accuracy: 0.1650 - intron_TP: 1279.0000 - other_TN: 7614.0000 - other_TP: 0.0000e+00 - other_FP: 0.0000e+00 - mix_TN: 10445.0000 - exon_TN: 8049.0000 - mix_FP: 4669.0000 - exon_FP: 1645.0000 - mix_TP: 0.0000e+00 - other_FN: 7500.0000 - intron_TN: 6614.0000 - val_loss: 1.4649 - val_acc: 0.1230 - val_exon_FN: 2576.0000 - val_mix_FN: 0.0000e+00 - val_intron_FN: 696.0000 - val_exon_TP: 718.0000 - val_intron_FP: 5345.0000 - val_categorical_accuracy: 0.1230 - val_intron_TP: 793.0000 - val_other_TN: 4783.0000 - val_other_TP: 0.0000e+00 - val_other_FP: 0.0000e+00 - val_mix_TN: 8375.0000 - val_exon_TN: 7470.0000 - val_mix_FP: 3908.0000 - val_exon_FP: 1519.0000 - val_mix_TP: 0.0000e+00 - val_other_FN: 7500.0000 - val_intron_TN: 5449.0000\n",
      "Epoch 4/1000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 1.4632 - acc: 0.1650 - exon_FN: 4205.0000 - mix_FN: 0.0000e+00 - intron_FN: 915.0000 - exon_TP: 1215.0000 - intron_FP: 6306.0000 - categorical_accuracy: 0.1650 - intron_TP: 1279.0000 - other_TN: 7614.0000 - other_TP: 0.0000e+00 - other_FP: 0.0000e+00 - mix_TN: 10445.0000 - exon_TN: 8049.0000 - mix_FP: 4669.0000 - exon_FP: 1645.0000 - mix_TP: 0.0000e+00 - other_FN: 7500.0000 - intron_TN: 6614.0000 - val_loss: 1.4487 - val_acc: 0.1230 - val_exon_FN: 2576.0000 - val_mix_FN: 0.0000e+00 - val_intron_FN: 696.0000 - val_exon_TP: 718.0000 - val_intron_FP: 5345.0000 - val_categorical_accuracy: 0.1230 - val_intron_TP: 793.0000 - val_other_TN: 4783.0000 - val_other_TP: 0.0000e+00 - val_other_FP: 0.0000e+00 - val_mix_TN: 8375.0000 - val_exon_TN: 7470.0000 - val_mix_FP: 3908.0000 - val_exon_FP: 1519.0000 - val_mix_TP: 0.0000e+00 - val_other_FN: 7500.0000 - val_intron_TN: 5449.0000\n",
      "Epoch 5/1000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 1.4482 - acc: 0.1650 - exon_FN: 4205.0000 - mix_FN: 0.0000e+00 - intron_FN: 915.0000 - exon_TP: 1215.0000 - intron_FP: 6306.0000 - categorical_accuracy: 0.1650 - intron_TP: 1279.0000 - other_TN: 7614.0000 - other_TP: 0.0000e+00 - other_FP: 0.0000e+00 - mix_TN: 10445.0000 - exon_TN: 8049.0000 - mix_FP: 4669.0000 - exon_FP: 1645.0000 - mix_TP: 0.0000e+00 - other_FN: 7500.0000 - intron_TN: 6614.0000 - val_loss: 1.4325 - val_acc: 0.1230 - val_exon_FN: 2576.0000 - val_mix_FN: 0.0000e+00 - val_intron_FN: 696.0000 - val_exon_TP: 718.0000 - val_intron_FP: 5345.0000 - val_categorical_accuracy: 0.1230 - val_intron_TP: 793.0000 - val_other_TN: 4783.0000 - val_other_TP: 0.0000e+00 - val_other_FP: 0.0000e+00 - val_mix_TN: 8375.0000 - val_exon_TN: 7470.0000 - val_mix_FP: 3908.0000 - val_exon_FP: 1519.0000 - val_mix_TP: 0.0000e+00 - val_other_FN: 7500.0000 - val_intron_TN: 5449.0000\n",
      "Epoch 6/1000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 1.4333 - acc: 0.1650 - exon_FN: 4205.0000 - mix_FN: 0.0000e+00 - intron_FN: 915.0000 - exon_TP: 1215.0000 - intron_FP: 6306.0000 - categorical_accuracy: 0.1650 - intron_TP: 1279.0000 - other_TN: 7614.0000 - other_TP: 0.0000e+00 - other_FP: 0.0000e+00 - mix_TN: 10445.0000 - exon_TN: 8049.0000 - mix_FP: 4669.0000 - exon_FP: 1645.0000 - mix_TP: 0.0000e+00 - other_FN: 7500.0000 - intron_TN: 6614.0000 - val_loss: 1.4164 - val_acc: 0.1230 - val_exon_FN: 2576.0000 - val_mix_FN: 0.0000e+00 - val_intron_FN: 696.0000 - val_exon_TP: 718.0000 - val_intron_FP: 5345.0000 - val_categorical_accuracy: 0.1230 - val_intron_TP: 793.0000 - val_other_TN: 4783.0000 - val_other_TP: 0.0000e+00 - val_other_FP: 0.0000e+00 - val_mix_TN: 8375.0000 - val_exon_TN: 7470.0000 - val_mix_FP: 3908.0000 - val_exon_FP: 1519.0000 - val_mix_TP: 0.0000e+00 - val_other_FN: 7500.0000 - val_intron_TN: 5449.0000\n",
      "Epoch 7/1000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 1.4186 - acc: 0.1650 - exon_FN: 4205.0000 - mix_FN: 0.0000e+00 - intron_FN: 915.0000 - exon_TP: 1215.0000 - intron_FP: 6306.0000 - categorical_accuracy: 0.1650 - intron_TP: 1279.0000 - other_TN: 7614.0000 - other_TP: 0.0000e+00 - other_FP: 0.0000e+00 - mix_TN: 10445.0000 - exon_TN: 8049.0000 - mix_FP: 4669.0000 - exon_FP: 1645.0000 - mix_TP: 0.0000e+00 - other_FN: 7500.0000 - intron_TN: 6614.0000 - val_loss: 1.4006 - val_acc: 0.1230 - val_exon_FN: 2576.0000 - val_mix_FN: 0.0000e+00 - val_intron_FN: 696.0000 - val_exon_TP: 718.0000 - val_intron_FP: 5345.0000 - val_categorical_accuracy: 0.1230 - val_intron_TP: 793.0000 - val_other_TN: 4783.0000 - val_other_TP: 0.0000e+00 - val_other_FP: 0.0000e+00 - val_mix_TN: 8375.0000 - val_exon_TN: 7470.0000 - val_mix_FP: 3908.0000 - val_exon_FP: 1519.0000 - val_mix_TP: 0.0000e+00 - val_other_FN: 7500.0000 - val_intron_TN: 5449.0000\n",
      "Epoch 8/1000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.4040 - acc: 0.1650 - exon_FN: 4205.0000 - mix_FN: 0.0000e+00 - intron_FN: 915.0000 - exon_TP: 1215.0000 - intron_FP: 6306.0000 - categorical_accuracy: 0.1650 - intron_TP: 1279.0000 - other_TN: 7614.0000 - other_TP: 0.0000e+00 - other_FP: 0.0000e+00 - mix_TN: 10445.0000 - exon_TN: 8049.0000 - mix_FP: 4669.0000 - exon_FP: 1645.0000 - mix_TP: 0.0000e+00 - other_FN: 7500.0000 - intron_TN: 6614.0000 - val_loss: 1.3850 - val_acc: 0.1230 - val_exon_FN: 2576.0000 - val_mix_FN: 0.0000e+00 - val_intron_FN: 696.0000 - val_exon_TP: 718.0000 - val_intron_FP: 5345.0000 - val_categorical_accuracy: 0.1230 - val_intron_TP: 793.0000 - val_other_TN: 4783.0000 - val_other_TP: 0.0000e+00 - val_other_FP: 0.0000e+00 - val_mix_TN: 8375.0000 - val_exon_TN: 7470.0000 - val_mix_FP: 3908.0000 - val_exon_FP: 1519.0000 - val_mix_TP: 0.0000e+00 - val_other_FN: 7500.0000 - val_intron_TN: 5449.0000\n",
      "Epoch 9/1000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.3898 - acc: 0.1650 - exon_FN: 4205.0000 - mix_FN: 0.0000e+00 - intron_FN: 915.0000 - exon_TP: 1215.0000 - intron_FP: 6306.0000 - categorical_accuracy: 0.1650 - intron_TP: 1279.0000 - other_TN: 7614.0000 - other_TP: 0.0000e+00 - other_FP: 0.0000e+00 - mix_TN: 10445.0000 - exon_TN: 8049.0000 - mix_FP: 4669.0000 - exon_FP: 1645.0000 - mix_TP: 0.0000e+00 - other_FN: 7500.0000 - intron_TN: 6614.0000 - val_loss: 1.3697 - val_acc: 0.1230 - val_exon_FN: 2576.0000 - val_mix_FN: 0.0000e+00 - val_intron_FN: 696.0000 - val_exon_TP: 718.0000 - val_intron_FP: 5345.0000 - val_categorical_accuracy: 0.1230 - val_intron_TP: 793.0000 - val_other_TN: 4783.0000 - val_other_TP: 0.0000e+00 - val_other_FP: 0.0000e+00 - val_mix_TN: 8375.0000 - val_exon_TN: 7470.0000 - val_mix_FP: 3908.0000 - val_exon_FP: 1519.0000 - val_mix_TP: 0.0000e+00 - val_other_FN: 7500.0000 - val_intron_TN: 5449.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/1000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.3759 - acc: 0.1650 - exon_FN: 4205.0000 - mix_FN: 0.0000e+00 - intron_FN: 915.0000 - exon_TP: 1215.0000 - intron_FP: 6306.0000 - categorical_accuracy: 0.1650 - intron_TP: 1279.0000 - other_TN: 7614.0000 - other_TP: 0.0000e+00 - other_FP: 0.0000e+00 - mix_TN: 10445.0000 - exon_TN: 8049.0000 - mix_FP: 4669.0000 - exon_FP: 1645.0000 - mix_TP: 0.0000e+00 - other_FN: 7500.0000 - intron_TN: 6614.0000 - val_loss: 1.3548 - val_acc: 0.3255 - val_exon_FN: 2576.0000 - val_mix_FN: 0.0000e+00 - val_intron_FN: 696.0000 - val_exon_TP: 718.0000 - val_intron_FP: 5345.0000 - val_categorical_accuracy: 0.3255 - val_intron_TP: 793.0000 - val_other_TN: 3362.0000 - val_other_TP: 2487.0000 - val_other_FP: 1421.0000 - val_mix_TN: 12283.0000 - val_exon_TN: 7470.0000 - val_mix_FP: 0.0000e+00 - val_exon_FP: 1519.0000 - val_mix_TP: 0.0000e+00 - val_other_FN: 5013.0000 - val_intron_TN: 5449.0000\n",
      "Epoch 11/1000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 1.3623 - acc: 0.3398 - exon_FN: 4205.0000 - mix_FN: 0.0000e+00 - intron_FN: 915.0000 - exon_TP: 1215.0000 - intron_FP: 6306.0000 - categorical_accuracy: 0.3398 - intron_TP: 1279.0000 - other_TN: 5587.0000 - other_TP: 2642.0000 - other_FP: 2027.0000 - mix_TN: 15114.0000 - exon_TN: 8049.0000 - mix_FP: 0.0000e+00 - exon_FP: 1645.0000 - mix_TP: 0.0000e+00 - other_FN: 4858.0000 - intron_TN: 6614.0000 - val_loss: 1.3403 - val_acc: 0.3255 - val_exon_FN: 2576.0000 - val_mix_FN: 0.0000e+00 - val_intron_FN: 696.0000 - val_exon_TP: 718.0000 - val_intron_FP: 5345.0000 - val_categorical_accuracy: 0.3255 - val_intron_TP: 793.0000 - val_other_TN: 3362.0000 - val_other_TP: 2487.0000 - val_other_FP: 1421.0000 - val_mix_TN: 12283.0000 - val_exon_TN: 7470.0000 - val_mix_FP: 0.0000e+00 - val_exon_FP: 1519.0000 - val_mix_TP: 0.0000e+00 - val_other_FN: 5013.0000 - val_intron_TN: 5449.0000\n",
      "Epoch 12/1000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 1.3491 - acc: 0.3398 - exon_FN: 4205.0000 - mix_FN: 0.0000e+00 - intron_FN: 915.0000 - exon_TP: 1215.0000 - intron_FP: 6306.0000 - categorical_accuracy: 0.3398 - intron_TP: 1279.0000 - other_TN: 5587.0000 - other_TP: 2642.0000 - other_FP: 2027.0000 - mix_TN: 15114.0000 - exon_TN: 8049.0000 - mix_FP: 0.0000e+00 - exon_FP: 1645.0000 - mix_TP: 0.0000e+00 - other_FN: 4858.0000 - intron_TN: 6614.0000 - val_loss: 1.3261 - val_acc: 0.3255 - val_exon_FN: 2576.0000 - val_mix_FN: 0.0000e+00 - val_intron_FN: 696.0000 - val_exon_TP: 718.0000 - val_intron_FP: 5345.0000 - val_categorical_accuracy: 0.3255 - val_intron_TP: 793.0000 - val_other_TN: 3362.0000 - val_other_TP: 2487.0000 - val_other_FP: 1421.0000 - val_mix_TN: 12283.0000 - val_exon_TN: 7470.0000 - val_mix_FP: 0.0000e+00 - val_exon_FP: 1519.0000 - val_mix_TP: 0.0000e+00 - val_other_FN: 5013.0000 - val_intron_TN: 5449.0000\n",
      "Epoch 13/1000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 1.3362 - acc: 0.3398 - exon_FN: 4205.0000 - mix_FN: 0.0000e+00 - intron_FN: 915.0000 - exon_TP: 1215.0000 - intron_FP: 6306.0000 - categorical_accuracy: 0.3398 - intron_TP: 1279.0000 - other_TN: 5587.0000 - other_TP: 2642.0000 - other_FP: 2027.0000 - mix_TN: 15114.0000 - exon_TN: 8049.0000 - mix_FP: 0.0000e+00 - exon_FP: 1645.0000 - mix_TP: 0.0000e+00 - other_FN: 4858.0000 - intron_TN: 6614.0000 - val_loss: 1.3123 - val_acc: 0.3255 - val_exon_FN: 2576.0000 - val_mix_FN: 0.0000e+00 - val_intron_FN: 696.0000 - val_exon_TP: 718.0000 - val_intron_FP: 5345.0000 - val_categorical_accuracy: 0.3255 - val_intron_TP: 793.0000 - val_other_TN: 3362.0000 - val_other_TP: 2487.0000 - val_other_FP: 1421.0000 - val_mix_TN: 12283.0000 - val_exon_TN: 7470.0000 - val_mix_FP: 0.0000e+00 - val_exon_FP: 1519.0000 - val_mix_TP: 0.0000e+00 - val_other_FN: 5013.0000 - val_intron_TN: 5449.0000\n",
      "Epoch 14/1000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 1.3238 - acc: 0.3398 - exon_FN: 4205.0000 - mix_FN: 0.0000e+00 - intron_FN: 915.0000 - exon_TP: 1215.0000 - intron_FP: 6306.0000 - categorical_accuracy: 0.3398 - intron_TP: 1279.0000 - other_TN: 5587.0000 - other_TP: 2642.0000 - other_FP: 2027.0000 - mix_TN: 15114.0000 - exon_TN: 8049.0000 - mix_FP: 0.0000e+00 - exon_FP: 1645.0000 - mix_TP: 0.0000e+00 - other_FN: 4858.0000 - intron_TN: 6614.0000 - val_loss: 1.2989 - val_acc: 0.3255 - val_exon_FN: 2576.0000 - val_mix_FN: 0.0000e+00 - val_intron_FN: 696.0000 - val_exon_TP: 718.0000 - val_intron_FP: 5345.0000 - val_categorical_accuracy: 0.3255 - val_intron_TP: 793.0000 - val_other_TN: 3362.0000 - val_other_TP: 2487.0000 - val_other_FP: 1421.0000 - val_mix_TN: 12283.0000 - val_exon_TN: 7470.0000 - val_mix_FP: 0.0000e+00 - val_exon_FP: 1519.0000 - val_mix_TP: 0.0000e+00 - val_other_FN: 5013.0000 - val_intron_TN: 5449.0000\n",
      "Epoch 15/1000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.3117 - acc: 0.3398 - exon_FN: 4205.0000 - mix_FN: 0.0000e+00 - intron_FN: 915.0000 - exon_TP: 1215.0000 - intron_FP: 6306.0000 - categorical_accuracy: 0.3398 - intron_TP: 1279.0000 - other_TN: 5587.0000 - other_TP: 2642.0000 - other_FP: 2027.0000 - mix_TN: 15114.0000 - exon_TN: 8049.0000 - mix_FP: 0.0000e+00 - exon_FP: 1645.0000 - mix_TP: 0.0000e+00 - other_FN: 4858.0000 - intron_TN: 6614.0000 - val_loss: 1.2860 - val_acc: 0.3255 - val_exon_FN: 2576.0000 - val_mix_FN: 0.0000e+00 - val_intron_FN: 696.0000 - val_exon_TP: 718.0000 - val_intron_FP: 5345.0000 - val_categorical_accuracy: 0.3255 - val_intron_TP: 793.0000 - val_other_TN: 3362.0000 - val_other_TP: 2487.0000 - val_other_FP: 1421.0000 - val_mix_TN: 12283.0000 - val_exon_TN: 7470.0000 - val_mix_FP: 0.0000e+00 - val_exon_FP: 1519.0000 - val_mix_TP: 0.0000e+00 - val_other_FN: 5013.0000 - val_intron_TN: 5449.0000\n",
      "Epoch 16/1000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.3000 - acc: 0.3398 - exon_FN: 4205.0000 - mix_FN: 0.0000e+00 - intron_FN: 915.0000 - exon_TP: 1215.0000 - intron_FP: 6306.0000 - categorical_accuracy: 0.3398 - intron_TP: 1279.0000 - other_TN: 5587.0000 - other_TP: 2642.0000 - other_FP: 2027.0000 - mix_TN: 15114.0000 - exon_TN: 8049.0000 - mix_FP: 0.0000e+00 - exon_FP: 1645.0000 - mix_TP: 0.0000e+00 - other_FN: 4858.0000 - intron_TN: 6614.0000 - val_loss: 1.2734 - val_acc: 0.3255 - val_exon_FN: 2576.0000 - val_mix_FN: 0.0000e+00 - val_intron_FN: 696.0000 - val_exon_TP: 718.0000 - val_intron_FP: 5345.0000 - val_categorical_accuracy: 0.3255 - val_intron_TP: 793.0000 - val_other_TN: 3362.0000 - val_other_TP: 2487.0000 - val_other_FP: 1421.0000 - val_mix_TN: 12283.0000 - val_exon_TN: 7470.0000 - val_mix_FP: 0.0000e+00 - val_exon_FP: 1519.0000 - val_mix_TP: 0.0000e+00 - val_other_FN: 5013.0000 - val_intron_TN: 5449.0000\n",
      "Epoch 17/1000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.2887 - acc: 0.3398 - exon_FN: 4205.0000 - mix_FN: 0.0000e+00 - intron_FN: 915.0000 - exon_TP: 1215.0000 - intron_FP: 6306.0000 - categorical_accuracy: 0.3398 - intron_TP: 1279.0000 - other_TN: 5587.0000 - other_TP: 2642.0000 - other_FP: 2027.0000 - mix_TN: 15114.0000 - exon_TN: 8049.0000 - mix_FP: 0.0000e+00 - exon_FP: 1645.0000 - mix_TP: 0.0000e+00 - other_FN: 4858.0000 - intron_TN: 6614.0000 - val_loss: 1.2612 - val_acc: 0.4083 - val_exon_FN: 2576.0000 - val_mix_FN: 0.0000e+00 - val_intron_FN: 913.0000 - val_exon_TP: 718.0000 - val_intron_FP: 3472.0000 - val_categorical_accuracy: 0.4083 - val_intron_TP: 576.0000 - val_other_TN: 2506.0000 - val_other_TP: 3721.0000 - val_other_FP: 2277.0000 - val_mix_TN: 12283.0000 - val_exon_TN: 7470.0000 - val_mix_FP: 0.0000e+00 - val_exon_FP: 1519.0000 - val_mix_TP: 0.0000e+00 - val_other_FN: 3779.0000 - val_intron_TN: 7322.0000\n",
      "Epoch 18/1000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.2779 - acc: 0.3961 - exon_FN: 4205.0000 - mix_FN: 0.0000e+00 - intron_FN: 1291.0000 - exon_TP: 1215.0000 - intron_FP: 3911.0000 - categorical_accuracy: 0.3961 - intron_TP: 903.0000 - other_TN: 4042.0000 - other_TP: 3868.0000 - other_FP: 3572.0000 - mix_TN: 15114.0000 - exon_TN: 8049.0000 - mix_FP: 0.0000e+00 - exon_FP: 1645.0000 - mix_TP: 0.0000e+00 - other_FN: 3632.0000 - intron_TN: 9009.0000 - val_loss: 1.2494 - val_acc: 0.5677 - val_exon_FN: 2576.0000 - val_mix_FN: 0.0000e+00 - val_intron_FN: 1489.0000 - val_exon_TP: 718.0000 - val_intron_FP: 0.0000e+00 - val_categorical_accuracy: 0.5677 - val_intron_TP: 0.0000e+00 - val_other_TN: 992.0000 - val_other_TP: 6255.0000 - val_other_FP: 3791.0000 - val_mix_TN: 12283.0000 - val_exon_TN: 7470.0000 - val_mix_FP: 0.0000e+00 - val_exon_FP: 1519.0000 - val_mix_TP: 0.0000e+00 - val_other_FN: 1245.0000 - val_intron_TN: 10794.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/1000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 1.2674 - acc: 0.4917 - exon_FN: 4205.0000 - mix_FN: 0.0000e+00 - intron_FN: 2194.0000 - exon_TP: 1215.0000 - intron_FP: 0.0000e+00 - categorical_accuracy: 0.4917 - intron_TP: 0.0000e+00 - other_TN: 1577.0000 - other_TP: 6217.0000 - other_FP: 6037.0000 - mix_TN: 15114.0000 - exon_TN: 8049.0000 - mix_FP: 0.0000e+00 - exon_FP: 1645.0000 - mix_TP: 0.0000e+00 - other_FN: 1283.0000 - intron_TN: 12920.0000 - val_loss: 1.2381 - val_acc: 0.5677 - val_exon_FN: 2576.0000 - val_mix_FN: 0.0000e+00 - val_intron_FN: 1489.0000 - val_exon_TP: 718.0000 - val_intron_FP: 0.0000e+00 - val_categorical_accuracy: 0.5677 - val_intron_TP: 0.0000e+00 - val_other_TN: 992.0000 - val_other_TP: 6255.0000 - val_other_FP: 3791.0000 - val_mix_TN: 12283.0000 - val_exon_TN: 7470.0000 - val_mix_FP: 0.0000e+00 - val_exon_FP: 1519.0000 - val_mix_TP: 0.0000e+00 - val_other_FN: 1245.0000 - val_intron_TN: 10794.0000\n",
      "Epoch 20/1000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 1.2573 - acc: 0.4917 - exon_FN: 4205.0000 - mix_FN: 0.0000e+00 - intron_FN: 2194.0000 - exon_TP: 1215.0000 - intron_FP: 0.0000e+00 - categorical_accuracy: 0.4917 - intron_TP: 0.0000e+00 - other_TN: 1577.0000 - other_TP: 6217.0000 - other_FP: 6037.0000 - mix_TN: 15114.0000 - exon_TN: 8049.0000 - mix_FP: 0.0000e+00 - exon_FP: 1645.0000 - mix_TP: 0.0000e+00 - other_FN: 1283.0000 - intron_TN: 12920.0000 - val_loss: 1.2271 - val_acc: 0.5677 - val_exon_FN: 2576.0000 - val_mix_FN: 0.0000e+00 - val_intron_FN: 1489.0000 - val_exon_TP: 718.0000 - val_intron_FP: 0.0000e+00 - val_categorical_accuracy: 0.5677 - val_intron_TP: 0.0000e+00 - val_other_TN: 992.0000 - val_other_TP: 6255.0000 - val_other_FP: 3791.0000 - val_mix_TN: 12283.0000 - val_exon_TN: 7470.0000 - val_mix_FP: 0.0000e+00 - val_exon_FP: 1519.0000 - val_mix_TP: 0.0000e+00 - val_other_FN: 1245.0000 - val_intron_TN: 10794.0000\n",
      "Epoch 21/1000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 1.2476 - acc: 0.4917 - exon_FN: 4205.0000 - mix_FN: 0.0000e+00 - intron_FN: 2194.0000 - exon_TP: 1215.0000 - intron_FP: 0.0000e+00 - categorical_accuracy: 0.4917 - intron_TP: 0.0000e+00 - other_TN: 1577.0000 - other_TP: 6217.0000 - other_FP: 6037.0000 - mix_TN: 15114.0000 - exon_TN: 8049.0000 - mix_FP: 0.0000e+00 - exon_FP: 1645.0000 - mix_TP: 0.0000e+00 - other_FN: 1283.0000 - intron_TN: 12920.0000 - val_loss: 1.2166 - val_acc: 0.5677 - val_exon_FN: 2576.0000 - val_mix_FN: 0.0000e+00 - val_intron_FN: 1489.0000 - val_exon_TP: 718.0000 - val_intron_FP: 0.0000e+00 - val_categorical_accuracy: 0.5677 - val_intron_TP: 0.0000e+00 - val_other_TN: 992.0000 - val_other_TP: 6255.0000 - val_other_FP: 3791.0000 - val_mix_TN: 12283.0000 - val_exon_TN: 7470.0000 - val_mix_FP: 0.0000e+00 - val_exon_FP: 1519.0000 - val_mix_TP: 0.0000e+00 - val_other_FN: 1245.0000 - val_intron_TN: 10794.0000\n",
      "Epoch 22/1000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-63808a863b3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mpipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcompiler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mworker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/sequence_annotation/sequence_annotation/pipeline/pipeline.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_before_execute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_prompt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Executing...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_after_execute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_compile_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sequence_annotation/sequence_annotation/pipeline/pipeline.py\u001b[0m in \u001b[0;36m_execute\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Start working('\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%Y-%m-%d %H:%M:%S\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgmtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\")\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_worker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mtime_spend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mend_time\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sequence_annotation/sequence_annotation/processor/worker/train_worker.py\u001b[0m in \u001b[0;36mwork\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;34m\"\"\"Train model\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sequence_annotation/sequence_annotation/pipeline/wrapper.py\u001b[0m in \u001b[0;36mfit_generator_wrapper\u001b[0;34m(model, data_)\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'validation'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         return model.fit_generator(generator=data['training'],\n\u001b[0;32m---> 12\u001b[0;31m                                    validation_data=data['validation'],*args,**argws)\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfit_generator_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m                 \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    593\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    596\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_qsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"'timeout' must be a non-negative number\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras import optimizers\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "builder = SeqAnnModelBuilder(4,4,cnn_layer=0,rnn_layer=0,softmax_unit=None)\n",
    "compiler = AnnSeqCompiler(Adam(lr=1e-2),'categorical_crossentropy',\n",
    "                          dynamic_weight_method=None,\n",
    "                          ann_types=selected_seqs.ANN_TYPES,values_to_ignore=0,\n",
    "                          metrics=[Accuracy(name='acc',values_to_ignore=0)])\n",
    "data = AnnSeqData({'data':{'training':{'inputs':selected_fasta,\n",
    "                                       'answers':selected_seqs}\n",
    "                          },'ANN_TYPES':selected_seqs.ANN_TYPES},\n",
    "                  discard_invalid_seq=True,validation_split=0.5,\n",
    "                  do_validate=True,padding_value=0\n",
    "              \n",
    "                 )\n",
    "worker = TrainWorker(is_verbose_visible=True)\n",
    "callbacks = [ModelPlot('2018_11_29/model.png',\n",
    "                        show_shapes =True,\n",
    "                        show_layer_names =True),\n",
    "             TensorBoard('../io/logs/',write_graph=True, write_grads=True, write_images=True),\n",
    "             ResultHistory('2018_11_29/result.csv',period=3,verbose=True),\n",
    "             AdvancedModelCheckpoint('2018_11_29/weights/weights_{epoch:04d}.hdf5',period=1)]\n",
    "wrapper = fit_generator_wrapper_generator(verbose=1,batch_size=5,\n",
    "                                          epochs=1000,epoch_shuffle=True,callbacks=[])\n",
    "worker.wrapper=wrapper\n",
    "pipeline = Pipeline(builder,data,compiler,worker)\n",
    "\n",
    "pipeline.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CudnnRNNRelu(Layer):\n",
    "    def __init__(self, units, **kwargs):\n",
    "        self.units = units\n",
    "        self.state_size = units\n",
    "        super().__init__(**kwargs)\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config['units'] = self.units\n",
    "        return config\n",
    "    def build(self, input_shape):\n",
    "        self.kernel = CudnnCompatibleGRUCell(shape=(input_shape[-1], self.units),\n",
    "                                      initializer='random_uniform',\n",
    "                                      name='kernel')\n",
    "        self.bias = self.add_weight(shape=(1,self.units),\n",
    "                                      initializer='zeros',\n",
    "                                      name='bias')\n",
    "        self.activation =  ReLU()#noised_relu\n",
    "        self.built = True\n",
    "    def call(self, inputs, states):\n",
    "        prev_output = states[0]\n",
    "        inputs_ = K.dot(inputs, self.kernel)\n",
    "        output = self.activation(inputs_ + prev_output+self.bias)\n",
    "        return output, [output]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
