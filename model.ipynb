{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "# The GPU id to use, usually either \"0\" or \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1,2,3\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.8.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from os.path import abspath, expanduser\n",
    "sys.path.append(abspath(expanduser(\"/../..\")))\n",
    "import unittest\n",
    "from sequence_annotation.processor.compiler import SimpleCompiler,AnnSeqCompiler\n",
    "from sequence_annotation.model.model_processor import SimpleModel,ModelCreator,IModelProcessor\n",
    "from sequence_annotation.processor.data_processor import AnnSeqData,SimpleData\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation,Input\n",
    "from sequence_annotation.worker.train_worker import TrainWorker\n",
    "from sequence_annotation.worker.test_worker import TestWorker\n",
    "from sequence_annotation.pipeline.pipeline import Pipeline\n",
    "from sequence_annotation.genome_handler.seq_container import AnnSeqContainer\n",
    "from sequence_annotation.genome_handler.ann_seq_processor import class_count\n",
    "from sequence_annotation.data_handler.fasta import read_fasta\n",
    "from sequence_annotation.data_handler.json import read_json\n",
    "from sequence_annotation.data_handler.seq_converter import SeqConverter\n",
    "from sequence_annotation.pipeline.wrapper import fit_generator_wrapper_generator\n",
    "from sequence_annotation.pipeline.wrapper import evaluate_generator_wrapper_generator\n",
    "from sequence_annotation.model.callback import AdvancedModelCheckpoint,ResultHistory,ModelPlot\n",
    "from sequence_annotation.model.metric import BatchCount,TruePositive\n",
    "from sequence_annotation.model.stateful_metric import StatefulMetric\n",
    "from keras.callbacks import TensorBoard \n",
    "import numpy as np\n",
    "from keras.utils import plot_model\n",
    "from keras.callbacks import EarlyStopping\n",
    "from hyperas import optim\n",
    "from hyperas.distributions import choice, uniform\n",
    "from hyperopt import Trials, STATUS_OK, tpe\n",
    "import random\n",
    "from sequence_annotation.genome_handler.sequence import AnnSequence\n",
    "from sequence_annotation.genome_handler.seq_container import AnnSeqContainer\n",
    "from sequence_annotation.model.data_generator import DataGenerator\n",
    "from hyperopt import Trials, STATUS_OK, tpe,fmin, tpe,hp\n",
    "from keras.layers import BatchNormalization, ReLU, Conv1D, Add, Dropout, Concatenate,Layer,LSTM,Bidirectional,RNN,Masking,SimpleRNNCell\n",
    "from keras.engine.training import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasta = read_fasta('gene_info/data/2018_11_24/Araport11_exon_2018_11_24_merged_with_coordinate_file_megred_exon_dist_to_five_1000_dist_to_three_500_merged.fasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deepdish as dd\n",
    "h5=dd.io.load('gene_info/data/2018_11_24/Araport11_exon_2018_11_24_merged_with_coordinate_file_megred_exon_dist_to_five_1000_dist_to_three_500_merged.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_seqs = AnnSeqContainer().from_dict(h5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Activation\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "import keras\n",
    "\n",
    "\n",
    "from keras.utils.generic_utils import CustomObjectScope\n",
    "from keras.utils import multi_gpu_model\n",
    "class SeqAnnModelBuilder(IModelProcessor):\n",
    "    def __init__(self,setting,input_dim,output_dim):\n",
    "        self._record = {'setting':setting,\n",
    "                        'input_dim':input_dim,\n",
    "                        'output_dim':output_dim}\n",
    "        self._setting = setting\n",
    "        self._input_dim = input_dim\n",
    "        self._output_dim = output_dim\n",
    "    def process(self):\n",
    "        model = Sequential()\n",
    "        inputs = Input(shape=(None,self._input_dim),name='Input')\n",
    "        inputs_ = Masking(mask_value=0,name='mask')(inputs)\n",
    "        previous_layer = inputs_\n",
    "        previous_input = inputs_\n",
    "        cnn_number = 16\n",
    "        rnn_number = 0\n",
    "        for index in range(cnn_number):\n",
    "            if previous_layer!=previous_input:\n",
    "                input_ = Concatenate(name='CNN_concat_'+str(index))([previous_input,previous_layer])\n",
    "            else:\n",
    "                input_ = previous_input\n",
    "            cnn = MaskedConvolution1D(2,kernel_size=32,activation='relu',padding='same',name='cnn_'+str(index))(input_)\n",
    "            bn = BatchNormalization()(cnn)\n",
    "            previous_input = input_\n",
    "            previous_layer = bn\n",
    "        for index in range(rnn_number):\n",
    "            if previous_layer!=previous_input:\n",
    "                input_ = Concatenate(name='RNN_concat_'+str(index))([previous_input,previous_layer])\n",
    "            else:\n",
    "                input_ = previous_input\n",
    "            with CustomObjectScope({'IRNNCell' : IRNNCell}):\n",
    "                cnn_input = MaskedConvolution1D(8,kernel_size=1,activation=None,padding='same',name='rnn_cnn_'+str(index))(input_)\n",
    "                rnn_ = RNN(IRNNCell(8), return_sequences=True,name='rnn_'+str(index))\n",
    "                rnn = Bidirectional(rnn_,name='bidir_rnn_'+str(index))(cnn_input)\n",
    "                bn = BatchNormalization()(rnn)\n",
    "                previous_input = input_\n",
    "                previous_layer = bn\n",
    "        cnn = MaskedConvolution1D(self._output_dim,kernel_size=1,activation='softmax',name='predict',padding='same')(previous_layer)\n",
    "        outputs = cnn\n",
    "        self._model = Model(inputs=inputs, outputs=outputs)\n",
    "    @property\n",
    "    def model(self):\n",
    "        return self._model\n",
    "    @property\n",
    "    def record(self):\n",
    "        return self._record\n",
    "class IRNNCell(Layer):\n",
    "    def __init__(self, units, **kwargs):\n",
    "        self.units = units\n",
    "        self.state_size = units\n",
    "        super().__init__(**kwargs)\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config['units'] = self.units\n",
    "        return config\n",
    "    def build(self, input_shape):\n",
    "\n",
    "        #self.kernel = self.add_weight(shape=(input_shape[-1],self.units),\n",
    "        #                              initializer='glorot_uniform',\n",
    "        #                              name='kernel')\n",
    "        #self.gate_input_kernel = self.add_weight(\n",
    "        #    shape=(input_shape[-1], self.units),\n",
    "        #    initializer=keras.initializers.RandomNormal(),\n",
    "        #    name='gate_input_kernel')\n",
    "        #self.gate_recurrent_kernel = self.add_weight(\n",
    "        #    shape=( self.units,self.units),\n",
    "        #    initializer='identity',\n",
    "        #    name='gate_recurrent_kernel')\n",
    "        #self.gate_bias = self.add_weight(\n",
    "        #    shape=(1, self.units),\n",
    "        #    initializer='ones',\n",
    "        #    name='gate_bias')\n",
    "        #self.bias = self.add_weight(\n",
    "        #    shape=(1, self.units),\n",
    "        #    initializer='zeros',\n",
    "        #    name='bias')\n",
    "        self.activation =  Activation('relu')#noised_relu\n",
    "        #self.gate_activation = noised_symmetric_sigmoid\n",
    "        self.built = True\n",
    "    def call(self, inputs, states):\n",
    "        prev_output = states[0]\n",
    "        #gate_ = K.dot(prev_output,self.gate_recurrent_kernel)+self.gate_bias +K.dot(inputs,self.gate_input_kernel)\n",
    "        #gate = self.gate_activation(gate_)\n",
    "        #input_ = K.dot(inputs, self.kernel)\n",
    "        output = self.activation(inputs + prev_output)\n",
    "        #output = self.activation(input_ + prev_output + self.bias )\n",
    "        #output = self.activation(input_ * (1-gate) + prev_output*gate+self.bias )\n",
    "        return output, [output]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = Input((5,2))\n",
    "#mask = Masking(0)(i)\n",
    "m = Conv1D(filters=1,kernel_size=1,kernel_initializer='one',bias_initializer='one',padding='same')(i)\n",
    "model = Model(inputs=[i],outputs=[m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[2.],\n",
       "        [2.],\n",
       "        [9.],\n",
       "        [1.],\n",
       "        [3.]]], dtype=float32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(np.array([[[1,0],[0,1],[-1,9],[0,0],[1,1]]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mask(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.supports_masking = True\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def compute_mask(self, input_, input_mask=None):\n",
    "        return input_mask\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        if mask is not None:\n",
    "            mask = K.cast(mask, K.floatx())\n",
    "        return mask\n",
    "\n",
    "class AddOne(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.supports_masking = True\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def compute_mask(self, input_, input_mask=None):\n",
    "        # do not pass the mask to the next layers\n",
    "        return input_mask\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        return x + tf.Variable(1,dtype='float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute '_keras_shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-172-7ce9ffcb22ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAddOne\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m#m = MaskedConvolution1D(filters=1,kernel_size=1,kernel_initializer='one',bias_initializer='one',padding='same')(mask)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    495\u001b[0m                                    \u001b[0minput_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m                                    \u001b[0moutput_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m                                    arguments=user_kwargs)\n\u001b[0m\u001b[1;32m    498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m             \u001b[0;31m# Apply activity regularizer if any:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_add_inbound_node\u001b[0;34m(self, input_tensors, output_tensors, input_masks, output_masks, input_shapes, output_shapes, arguments)\u001b[0m\n\u001b[1;32m    563\u001b[0m         \u001b[0;31m# Update tensor history, _keras_shape and _uses_learning_phase.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m             \u001b[0moutput_tensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_shapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    566\u001b[0m             uses_lp = any(\n\u001b[1;32m    567\u001b[0m                 [getattr(x, '_uses_learning_phase', False)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute '_keras_shape'"
     ]
    }
   ],
   "source": [
    "i = Input((5,2))\n",
    "mask_layer = Masking(1.0)(i)\n",
    "o = Mask()(mask_layer)\n",
    "a = AddOne()(o)\n",
    "o = Mask()(a)\n",
    "#m = MaskedConvolution1D(filters=1,kernel_size=1,kernel_initializer='one',bias_initializer='one',padding='same')(mask)\n",
    "model = Model(inputs=[i],outputs=[o])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[[1,0],[0,1],[-1,9],[0,0],[1,1]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1, 0], [0, 1], [-1, 9], [0, 0], [1, 1]]]\n",
      "[array([[ 1.,  0.],\n",
      "       [ 0.,  1.],\n",
      "       [-1.,  9.],\n",
      "       [ 0.,  0.],\n",
      "       [ 0.,  0.]], dtype=float32)]\n",
      "[array([1., 1., 1., 1., 0.], dtype=float32)]\n",
      "[array([2., 2., 2., 2., 1.], dtype=float32)]\n",
      "[array([1., 1., 1., 1., 0.], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "from keras import backend   as K\n",
    "mask_output = K.function([model.layers[0].input], [model.layers[1].output])(data)\n",
    "lambda_output = K.function([model.layers[0].input], [model.layers[2].output])(data)\n",
    "lambda_output2 = K.function([model.layers[0].input], [model.layers[3].output])(data)\n",
    "lambda_output3 = K.function([model.layers[0].input], [model.layers[4].output])(data)\n",
    "print(data)\n",
    "print(mask_output)\n",
    "print(lambda_output)\n",
    "print(lambda_output2)\n",
    "print(lambda_output3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "if hasattr(config,\"gpu_options\"):\n",
    "    config.gpu_options.allow_growth=True\n",
    "sess = tf.Session(config=config)\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import median\n",
    "median_len = median([len(seq) for seq in ann_seqs])\n",
    "median_seqs = AnnSeqContainer()\n",
    "median_seqs.ANN_TYPES = ann_seqs.ANN_TYPES\n",
    "median_fasta = {}\n",
    "number = 0\n",
    "for seq in ann_seqs:\n",
    "    if len(seq) < median_len:\n",
    "        median_seqs.add(seq)\n",
    "        median_fasta[seq.id]=fasta[seq.id]\n",
    "        number += 1\n",
    "    if number >= 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'exon': 1843.0, 'intron': 0.0, 'mix': 0.0, 'other': 1500.0}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_count(median_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing model..\n",
      "Processing data...\n",
      "Compiling model...\n",
      "WARNING:tensorflow:Variable *= will be deprecated. Use variable.assign_mul if you want assignment to the variable value or 'x = x * y' if you want a new python Tensor object.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sequence_annotation/sequence_annotation/genome_handler/ann_seq_processor.py:186: UserWarning: \n",
      "\n",
      "!!!\n",
      "\tDNA sequence will be rearranged from 5' to 3'.\n",
      "\tThe plus strand sequence will stay the same, but the minus strand sequence will be flipped!\n",
      "!!!\n",
      "\n",
      "  warnings.warn(warn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing worker...\n",
      "Executing...\n",
      "Start working(2018-11-29 17:21:26)\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 5s 5s/step - loss: 1.5084 - batch_count: 1.0000 - exon_TP: 0.0000e+00 - other_TN: 0.0000e+00 - exon_FP: 0.0000e+00 - mix_TN: 0.0000e+00 - exon_TN: 0.0000e+00 - other_TP: 0.0000e+00 - other_FP: 0.0000e+00 - mix_FN: 0.0000e+00 - intron_TN: 0.0000e+00 - other_FN: 0.0000e+00 - intron_FP: 0.0000e+00 - mix_FP: 0.0000e+00 - intron_TP: 0.0000e+00 - intron_FN: 0.0000e+00 - exon_FN: 0.0000e+00 - mix_TP: 0.0000e+00\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.4552 - batch_count: 1.0000 - exon_TP: 0.0000e+00 - other_TN: 0.0000e+00 - exon_FP: 0.0000e+00 - mix_TN: 0.0000e+00 - exon_TN: 0.0000e+00 - other_TP: 0.0000e+00 - other_FP: 0.0000e+00 - mix_FN: 0.0000e+00 - intron_TN: 0.0000e+00 - other_FN: 0.0000e+00 - intron_FP: 0.0000e+00 - mix_FP: 0.0000e+00 - intron_TP: 0.0000e+00 - intron_FN: 0.0000e+00 - exon_FN: 0.0000e+00 - mix_TP: 0.0000e+00\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.4006 - batch_count: 1.0000 - exon_TP: 0.0000e+00 - other_TN: 0.0000e+00 - exon_FP: 0.0000e+00 - mix_TN: 0.0000e+00 - exon_TN: 0.0000e+00 - other_TP: 0.0000e+00 - other_FP: 0.0000e+00 - mix_FN: 0.0000e+00 - intron_TN: 0.0000e+00 - other_FN: 0.0000e+00 - intron_FP: 0.0000e+00 - mix_FP: 0.0000e+00 - intron_TP: 0.0000e+00 - intron_FN: 0.0000e+00 - exon_FN: 0.0000e+00 - mix_TP: 0.0000e+00\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.3476 - batch_count: 1.0000 - exon_TP: 0.0000e+00 - other_TN: 0.0000e+00 - exon_FP: 0.0000e+00 - mix_TN: 0.0000e+00 - exon_TN: 0.0000e+00 - other_TP: 0.0000e+00 - other_FP: 0.0000e+00 - mix_FN: 0.0000e+00 - intron_TN: 0.0000e+00 - other_FN: 0.0000e+00 - intron_FP: 0.0000e+00 - mix_FP: 0.0000e+00 - intron_TP: 0.0000e+00 - intron_FN: 0.0000e+00 - exon_FN: 0.0000e+00 - mix_TP: 0.0000e+00\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.2950 - batch_count: 1.0000 - exon_TP: 0.0000e+00 - other_TN: 0.0000e+00 - exon_FP: 0.0000e+00 - mix_TN: 0.0000e+00 - exon_TN: 0.0000e+00 - other_TP: 0.0000e+00 - other_FP: 0.0000e+00 - mix_FN: 0.0000e+00 - intron_TN: 0.0000e+00 - other_FN: 0.0000e+00 - intron_FP: 0.0000e+00 - mix_FP: 0.0000e+00 - intron_TP: 0.0000e+00 - intron_FN: 0.0000e+00 - exon_FN: 0.0000e+00 - mix_TP: 0.0000e+00\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.2454 - batch_count: 1.0000 - exon_TP: 0.0000e+00 - other_TN: 0.0000e+00 - exon_FP: 0.0000e+00 - mix_TN: 0.0000e+00 - exon_TN: 0.0000e+00 - other_TP: 0.0000e+00 - other_FP: 0.0000e+00 - mix_FN: 0.0000e+00 - intron_TN: 0.0000e+00 - other_FN: 0.0000e+00 - intron_FP: 0.0000e+00 - mix_FP: 0.0000e+00 - intron_TP: 0.0000e+00 - intron_FN: 0.0000e+00 - exon_FN: 0.0000e+00 - mix_TP: 0.0000e+00\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.2025 - batch_count: 1.0000 - exon_TP: 0.0000e+00 - other_TN: 0.0000e+00 - exon_FP: 0.0000e+00 - mix_TN: 0.0000e+00 - exon_TN: 0.0000e+00 - other_TP: 0.0000e+00 - other_FP: 0.0000e+00 - mix_FN: 0.0000e+00 - intron_TN: 0.0000e+00 - other_FN: 0.0000e+00 - intron_FP: 0.0000e+00 - mix_FP: 0.0000e+00 - intron_TP: 0.0000e+00 - intron_FN: 0.0000e+00 - exon_FN: 0.0000e+00 - mix_TP: 0.0000e+00\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 1.1679 - batch_count: 1.0000 - exon_TP: 0.0000e+00 - other_TN: 0.0000e+00 - exon_FP: 0.0000e+00 - mix_TN: 0.0000e+00 - exon_TN: 0.0000e+00 - other_TP: 0.0000e+00 - other_FP: 0.0000e+00 - mix_FN: 0.0000e+00 - intron_TN: 0.0000e+00 - other_FN: 0.0000e+00 - intron_FP: 0.0000e+00 - mix_FP: 0.0000e+00 - intron_TP: 0.0000e+00 - intron_FN: 0.0000e+00 - exon_FN: 0.0000e+00 - mix_TP: 0.0000e+00\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.1408 - batch_count: 1.0000 - exon_TP: 0.0000e+00 - other_TN: 0.0000e+00 - exon_FP: 0.0000e+00 - mix_TN: 0.0000e+00 - exon_TN: 0.0000e+00 - other_TP: 0.0000e+00 - other_FP: 0.0000e+00 - mix_FN: 0.0000e+00 - intron_TN: 0.0000e+00 - other_FN: 0.0000e+00 - intron_FP: 0.0000e+00 - mix_FP: 0.0000e+00 - intron_TP: 0.0000e+00 - intron_FN: 0.0000e+00 - exon_FN: 0.0000e+00 - mix_TP: 0.0000e+00\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.1191 - batch_count: 1.0000 - exon_TP: 0.0000e+00 - other_TN: 0.0000e+00 - exon_FP: 0.0000e+00 - mix_TN: 0.0000e+00 - exon_TN: 0.0000e+00 - other_TP: 0.0000e+00 - other_FP: 0.0000e+00 - mix_FN: 0.0000e+00 - intron_TN: 0.0000e+00 - other_FN: 0.0000e+00 - intron_FP: 0.0000e+00 - mix_FP: 0.0000e+00 - intron_TP: 0.0000e+00 - intron_FN: 0.0000e+00 - exon_FN: 0.0000e+00 - mix_TP: 0.0000e+00\n",
      "End working(2018-11-29 17:21:42)\n",
      "Spend time: 00:00:16\n"
     ]
    }
   ],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "builder = SeqAnnModelBuilder({},4,4)\n",
    "compiler = AnnSeqCompiler('adam','categorical_crossentropy',\n",
    "                          ann_types=median_seqs.ANN_TYPES,\n",
    "                          custom_metrics=[StatefulMetric(BatchCount())])\n",
    "data = AnnSeqData({'data':{'training':{'inputs':median_fasta,\n",
    "                                       'answers':median_seqs}\n",
    "                          },'ANN_TYPES':ann_seqs.ANN_TYPES},\n",
    "                  discard_invalid_seq=False,validation_split=0,\n",
    "                  do_validate=True,padding_value=0,\n",
    "              \n",
    "                 )\n",
    "worker = TrainWorker(is_verbose_visible=True)\n",
    "callbacks = [ModelPlot('2018_11_29/model.png',\n",
    "                        show_shapes =True,\n",
    "                        show_layer_names =True),\n",
    "             TensorBoard('../io/logs/',write_graph=True, write_grads=True, write_images=True),\n",
    "             ResultHistory('2018_11_29/result.csv',period=3,verbose=True),\n",
    "             AdvancedModelCheckpoint('2018_11_29/weights/weights_{epoch:03d}.hdf5',period=1)]\n",
    "wrapper = fit_generator_wrapper_generator(verbose=1,batch_size=1,\n",
    "                                          epochs=10,epoch_shuffle=True,callbacks=[])\n",
    "pipeline = Pipeline(builder,data,compiler,worker,\n",
    "                    wrapper,is_prompt_visible=True)\n",
    "\n",
    "pipeline.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.floor(3/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelOptimizer:\n",
    "    def __init__(self):\n",
    "        self.x_train, self.y_train, self.x_test, self.y_test=self._prepare_data()\n",
    "    def _prepare_data(self):\n",
    "        x,y=generator()\n",
    "        val_x,val_y=generator()\n",
    "        data = SimpleData({'training':{'inputs':x,'answers':y},\n",
    "                           'validation':{'inputs':val_x,'answers':val_y}})\n",
    "        data.before_process()\n",
    "        data.process()\n",
    "        data.after_process()\n",
    "        return (data.data['training']['inputs'],\n",
    "                data.data['training']['answers'],\n",
    "                data.data['validation']['inputs'],\n",
    "                data.data['validation']['answers'])\n",
    "    def _create_model(self,space):\n",
    "        builder = SeqAnnModelBuilder({},3,4)\n",
    "        builder.process()\n",
    "        simple_model = SimpleModel(builder.model)\n",
    "        return simple_model\n",
    "    def get_loss(self,space):\n",
    "        model = self._create_model(space)\n",
    "        compiler = AnnSeqCompiler('adam','categorical_crossentropy')\n",
    "        data = SimpleData({'training':{'inputs':self.x_train,'answers':self.y_train},\n",
    "                          'validation':{'inputs':self.x_test,'answers':self.y_test}})\n",
    "        worker = TrainWorker(is_verbose_visible=False)\n",
    "        wrapper = fit_generator_wrapper_generator(verbose=1,batch_size=1000,\n",
    "                                                  epochs=30,callbacks=[#ModelPlot(str(space['layer'])+'.png',show_shapes =True,\n",
    "                                                                        #          show_layer_names =True),\n",
    "                                                                        #ResultHistory(str(space['layer'])+'tsv',period=2,verbose=True),\n",
    "                                                                        #AdvancedModelCheckpoint('weights.{epoch:02d}.hdf5',period=2),\n",
    "                                                  #                      EarlyStopping(patience=5)\n",
    "                                                  ])\n",
    "        pipeline = Pipeline(model,data,compiler,worker,\n",
    "                            wrapper,is_prompt_visible=False)\n",
    "\n",
    "        pipeline.execute()\n",
    "        #get the highest validation accuracy of the training epochs\n",
    "        val_loss = np.amax(worker.result['loss']) \n",
    "        #self._loss = -validation_acc\n",
    "        print('Best validation loss of epoch:', val_loss)\n",
    "        return {'loss': val_loss, 'status': STATUS_OK, 'model': model.model,'space':space}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'generator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-946b87096bab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodelOptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-cffb112591d6>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mModelOptimizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prepare_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-cffb112591d6>\u001b[0m in \u001b[0;36m_prepare_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prepare_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_y\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         data = SimpleData({'training':{'inputs':x,'answers':y},\n",
      "\u001b[0;31mNameError\u001b[0m: name 'generator' is not defined"
     ]
    }
   ],
   "source": [
    "modelOptimizer = ModelOptimizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = Trials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = fmin(modelOptimizer.get_loss, space={'layer':hp.choice('nubmer',[_ for _ in range(1,11)])}\n",
    "           , algo=tpe.suggest ,trials=trials, max_evals=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
