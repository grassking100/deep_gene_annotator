{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "import sys\n",
    "from os.path import abspath, expanduser\n",
    "sys.path.append(abspath(expanduser(\"../RNN\")))\n",
    "sys.path.append(abspath(expanduser(\"../sequence_annotation\")))\n",
    "import torch\n",
    "import time\n",
    "import numpy as np\n",
    "from sequence_annotation.visual.visual import visual_ann_seq,visual_ann_genome\n",
    "from sequence_annotation.genome_handler import ann_seq_processor\n",
    "import deepdish as dd\n",
    "from sequence_annotation.data_handler.fasta import read_fasta\n",
    "from sequence_annotation.genome_handler.sequence import AnnSequence\n",
    "from sequence_annotation.genome_handler.seq_container import AnnSeqContainer\n",
    "from sequence_annotation.function.data_generator import SeqGenerator\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "from numpy import median\n",
    "from sequence_annotation.genome_handler.ann_genome_processor import simplify_genome,get_genome_region_info\n",
    "from sequence_annotation.data_handler.seq_converter import SeqConverter\n",
    "from sequence_annotation.pytorch.customize_layer import Concat,PWM#,GatedIndRnnCell\n",
    "from rnn import RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "h5=dd.io.load('../io/Arabidopsis_thaliana/data/2018_11_27/Araport11_exon_2018_11_27_merged_with_coordinate_file_megred_exon_dist_to_five_1000_dist_to_three_500_merged.h5')\n",
    "fasta = read_fasta('../io/Arabidopsis_thaliana/data/2018_11_27/Araport11_exon_2018_11_27_merged_with_coordinate_file_megred_exon_dist_to_five_1000_dist_to_three_500_merged.fasta')\n",
    "ann_seqs = AnnSeqContainer().from_dict(h5)\n",
    "seqs_len = [len(seq) for seq in ann_seqs]\n",
    "seqs_len.sort()\n",
    "len_threshold = seqs_len[:int(len(seqs_len)/100)][-1]\n",
    "inner_fasta = {}\n",
    "for seq in ann_seqs:\n",
    "    if len(seq) <= len_threshold:\n",
    "        inner_fasta[seq.id]=fasta[seq.id]\n",
    "    elif len(seq) >= len_threshold*3:\n",
    "        outlier_name = seq.id\n",
    "keys = list(inner_fasta.keys())\n",
    "random.shuffle(keys)\n",
    "selected_seqs = AnnSeqContainer()\n",
    "selected_seqs.ANN_TYPES = ann_seqs.ANN_TYPES\n",
    "selected_fasta = {}\n",
    "number = 0\n",
    "for seq_id in keys:\n",
    "    selected_seqs.add(ann_seqs.get(seq_id))\n",
    "    selected_fasta[seq_id]=inner_fasta[seq_id]\n",
    "    number += 1\n",
    "selected_seqs = simplify_genome(selected_seqs,{'gene':['exon','intron','mix'],'other':['other']})\n",
    "print(number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from torch.nn.init import ones_,zeros_,uniform_,normal_,constant_,eye_\n",
    "from sequence_annotation.pytorch.customize_layer import noisy_hard_tanh,noisy_hard_sigmoid,noisy_relu\n",
    "from torch.nn import Hardtanh,Tanh\n",
    "\n",
    "cell_func = lambda input_size,hidden_size: GatedIndRnnCell(input_size=input_size,hidden_size=hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sequence_annotation.pytorch.customize_layer import init_GRU\n",
    "#from torch.nn import Hardtanh, Sigmoid\n",
    "class Model(nn.Module):\n",
    "    def __init__(self,out_num,in_num=4,cnn_num=8,rnn_num=2,cnn_out_num=16,rnn_out_num=4):\n",
    "        super().__init__()\n",
    "        self.cnns = []\n",
    "        self.softmax_cnns = []\n",
    "        self.rnns = []\n",
    "        self.cnn_bns = []\n",
    "        self.rnn_bns = []\n",
    "        self.in_num=in_num\n",
    "        self.out_num = out_num\n",
    "        self.cnn_out_num=cnn_out_num\n",
    "        self.rnn_out_num=rnn_out_num\n",
    "        self.cnn_num=cnn_num\n",
    "        self.rnn_num=rnn_num\n",
    "        self._build_layers()\n",
    "    def _build_layers(self):\n",
    "        in_num = self.in_num\n",
    "        for index in range(1,1+self.cnn_num):\n",
    "            self.softmax_cnns.append(nn.Conv1d(in_channels=in_num,kernel_size=32,\n",
    "                                               out_channels=self.cnn_out_num).cuda())\n",
    "            self.cnns.append(nn.Conv1d(in_channels=in_num,kernel_size=32,\n",
    "                                       out_channels=self.cnn_out_num).cuda())\n",
    "            self.cnn_bns.append(nn.LayerNorm(self.cnn_out_num).cuda())\n",
    "            in_num += self.cnn_out_num\n",
    "        self.last_cnn_bn = nn.LayerNorm(in_num).cuda()\n",
    "        #self.linear = IndLinear(in_num).cuda()\n",
    "        for index in range(self.rnn_num):\n",
    "            rnn = RNN([cell_func(in_num,self.rnn_out_num),cell_func(in_num,self.rnn_out_num)],\n",
    "                       bidirectional=True).cuda()\n",
    "            self.rnn_bns.append(nn.LayerNorm(in_num).cuda())\n",
    "            self.rnns.append(rnn)\n",
    "            in_num += (self.rnn_out_num*2)\n",
    "        if self.rnn_num>0:\n",
    "            in_num = (self.rnn_out_num*2*self.rnn_num)\n",
    "        self.last_bn = nn.LayerNorm(in_num).cuda()\n",
    "        self.last = nn.Conv1d(in_channels=in_num,kernel_size=1,out_channels=self.out_num).cuda()\n",
    "        for index,cnn_bn in enumerate(self.cnn_bns):\n",
    "            setattr(self, 'cnn_bn_'+str(index), cnn_bn)\n",
    "        for index,rnn_bn in enumerate(self.rnn_bns):\n",
    "            setattr(self, 'rnn_bn_'+str(index), rnn_bn)\n",
    "        for index,cnn in enumerate(self.cnns):\n",
    "            setattr(self, 'cnn_'+str(index), cnn)\n",
    "        for index,rnn in enumerate(self.rnns):\n",
    "            setattr(self, 'rnn_'+str(index), rnn)\n",
    "        self.reset_parameters()\n",
    "    def reset_parameters(self):\n",
    "        for layer in self.children():\n",
    "            layer.reset_parameters()\n",
    "        for cnn in self.cnns:\n",
    "            normal_(cnn.weight)\n",
    "            #torch.nn.init.xavier_uniform_(cnn.weight, gain=nn.init.calculate_gain('relu'))\n",
    "            constant_(cnn.bias,0)\n",
    "        for rnn in self.rnns:\n",
    "            if isinstance(rnn,nn.GRU):\n",
    "                init_GRU(rnn)\n",
    "        normal_(self.last.weight)\n",
    "        #torch.nn.init.xavier_uniform_(self.last.weight, gain=nn.init.calculate_gain('linear'))\n",
    "        constant_(self.last.bias,0)\n",
    "    def forward(self, x, lengths=None,return_values=False):\n",
    "        #X shape : N,C,L\n",
    "        figrue_output = {}\n",
    "        distribution_output = {}\n",
    "        input_ = x\n",
    "        index=0\n",
    "        for cnn,bn in zip(self.cnns,self.cnn_bns):\n",
    "            index+=1\n",
    "            cnn_x = cnn(x)\n",
    "            post_act_x = noisy_relu()(cnn_x,self.training)\n",
    "            post_act_x = bn(post_act_x.transpose(1, 2)).transpose(1, 2)\n",
    "            post_act_x = PWM()(post_act_x)\n",
    "            x,lengths = Concat(dim=1)([x,post_act_x],lengths)\n",
    "            figrue_output['x_'+str(index)+'_figure'] = x\n",
    "            figrue_output['cnn_x_'+str(index)+'_figure'] = cnn_x\n",
    "            figrue_output['post_act_x_'+str(index)+'_figure'] = post_act_x\n",
    "        x = self.last_cnn_bn(x.transpose(1, 2)).transpose(1, 2)\n",
    "        x = PWM()(x)\n",
    "        distribution_output['cnn_result'] = x\n",
    "        figrue_output['cnn_result_figure'] = x\n",
    "        x = x.transpose(1, 2)\n",
    "        all_rnns = []\n",
    "        gate_i_list = []\n",
    "        new_h_list = []\n",
    "        for index in range(len(self.rnns)):\n",
    "            rnn = self.rnns[index]\n",
    "            rnn_bn = self.rnn_bns[index]\n",
    "            #x= rnn_bn(x)\n",
    "            rnn_outputs = rnn(packed_x)\n",
    "            gate_i_list.append(rnn_outputs[rnn.output_names.index('gate_i')].transpose(1, 2))\n",
    "            new_h_list.append(rnn_outputs[rnn.output_names.index('new_h')].transpose(1, 2))\n",
    "            rnn_x = rnn_outputs[0]\n",
    "            #rnn_x -= 0.5\n",
    "            all_rnns.append(rnn_x)\n",
    "            #rnn_x = rnn_bn(rnn_x)\n",
    "            #n_x = PWM()(n_x.transpose(1, 2)).transpose(1, 2)\n",
    "            if (1+index)==len(self.rnns):\n",
    "                x = rnn_x\n",
    "            else:\n",
    "                x = torch.cat([x,rnn_x],2)\n",
    "            if isinstance(rnn,RNN):\n",
    "                for name,rnn_output in zip(rnn.output_names,rnn_outputs):\n",
    "                    if isinstance(rnn_output,PackedSequence):\n",
    "                        rnn_output,_ = pad_packed_sequence(rnn_output, batch_first=True)\n",
    "                    values = rnn_output.transpose(1,2)\n",
    "                    distribution_output[\"rnn_\"+str(index)+\"_\"+name] = values\n",
    "                    figrue_output[\"rnn_\"+str(index)+\"_\"+name+\"_figure\"] = values\n",
    "        \n",
    "        if len(all_rnns) > 0:\n",
    "            x = torch.cat(all_rnns,2)\n",
    "        #x = self.last_bn(x)\n",
    "        x = x.transpose(1, 2)\n",
    "        #figrue_output[\"last_bn\"] = x\n",
    "        x = self.last(x)\n",
    "        figrue_output[\"pre_softmax_figure\"] = x\n",
    "        x = F.softmax(x,dim=1)\n",
    "        if return_values:\n",
    "            return x,figrue_output,distribution_output\n",
    "        else:\n",
    "            return x,new_h_list+gate_i_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gene': 14301.0, 'other': 48000.0}"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sequence_annotation.genome_handler.utils import ann_count\n",
    "ann_count(selected_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GatedIndRnnCell(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self._gate_num = 1\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.gate_weights = torch.nn.Parameter(torch.empty(hidden_size, hidden_size+input_size))\n",
    "        self.weights_i = torch.nn.Parameter(torch.empty(hidden_size, input_size))\n",
    "        self.gate_bias = torch.nn.Parameter(torch.empty(hidden_size))\n",
    "        self.bn = nn.LayerNorm(hidden_size+ input_size).cuda()\n",
    "        self.gate_function =  noisy_hard_sigmoid(c=1)\n",
    "        self.recurrent_function = noisy_hard_sigmoid(c=1)\n",
    "        self.reset_parameters()\n",
    "        self.output_names = ['new_h','concat_input','pre_gate_i','gate_i','values_i','pre_h']\n",
    "    def reset_parameters(self):\n",
    "        gate_bound = (1/((self.input_size+self.hidden_size)))\n",
    "        input_bound = (1/(self.input_size))\n",
    "        uniform_(self.gate_weights,-gate_bound,gate_bound)\n",
    "        uniform_(self.weights_i,-input_bound,input_bound)\n",
    "        constant_(self.gate_bias,0.5)\n",
    "    def forward(self, input, state):\n",
    "        #input shape should be (number,feature size)\n",
    "        concat_input = torch.cat([input,state], dim=1)\n",
    "        pre_gate_i = F.linear(concat_input, self.gate_weights,self.gate_bias)\n",
    "        gate_i = self.gate_function(pre_gate_i,training=self.training)\n",
    "        values_i = F.linear(input, self.weights_i)\n",
    "        values_i = Tanh()(values_i)\n",
    "        pre_h = state+ values_i*gate_i\n",
    "        new_h = self.recurrent_function(pre_h,training=self.training)\n",
    "        return new_h,concat_input,pre_gate_i,gate_i,values_i,pre_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeqAnnlLoss(nn.Module):\n",
    "    def __init__(self, class_num,alphas=None, gamma=0,ignore_index=None):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "        self._ignore_index = ignore_index\n",
    "        self._class_num = class_num\n",
    "        self._alphas = alphas\n",
    "    def forward(self, output, target,spatial_weights=None):\n",
    "        \"\"\"data shape is N,C,L\"\"\"\n",
    "        pt = output[0]\n",
    "        gate_i = output[1]\n",
    "        center=0.5\n",
    "        gate_loss_ = ((center**2)-(torch.cat(gate_i,1)-center)**2).mean(1)\n",
    "        input_length = pt.shape[2]\n",
    "        if list(pt.shape) != list(target.shape):\n",
    "            target = target.transpose(0,2)[:input_length].transpose(0,2)\n",
    "        target = target.float()\n",
    "        if self._ignore_index is not None:\n",
    "            mask = (target.max(1)[0] != self._ignore_index).float()\n",
    "        decay_cooef = (1-pt)**self.gamma\n",
    "        loss_ =  -decay_cooef* (pt+1e-10).log() * target\n",
    "        if spatial_weights is not None:\n",
    "            if list(pt.shape) != list(spatial_weights.shape):\n",
    "                 spatial_weights = spatial_weights.transpose(0,2)[:input_length].transpose(0,2)\n",
    "            spatial_weights = torch.FloatTensor(spatial_weights).cuda()\n",
    "        if self._alphas is not None:\n",
    "            loss_ = loss_*self._alphas\n",
    "        loss_ = loss_.sum(1)\n",
    "        if self._ignore_index is not None:\n",
    "            gate_loss_ = gate_loss_*mask\n",
    "            loss_ = loss_*mask\n",
    "            loss = loss_.sum()/mask.sum()\n",
    "            gate_loss = gate_loss_.sum()/mask.sum()\n",
    "        else:\n",
    "            loss = loss_.mean()\n",
    "            gate_loss = gate_loss_.mean()\n",
    "        return loss + gate_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_num=len(selected_seqs.ANN_TYPES)\n",
    "model = Model(class_num,cnn_out_num=16,rnn_out_num=2,cnn_num=8,rnn_num=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data...\n",
      "Processing model..\n",
      "Compiling model...\n",
      "Processing worker...\n",
      "Executing...\n",
      "Start working(2019-02-17 08:54:06)\n",
      "1 {'val_loss': 0.8765599131584167, 'F1_gene': 0.4191321841073844, 'val_accuracy': 0.277872420972932, 'val_F1_gene': 0.4348985335505851, 'loss': 0.7831479012966156, 'accuracy': 0.26512791258940716, 'F1_other': 0.0, 'val_F1_other': 0.0}\n",
      "2 {'val_loss': 0.8378812670707703, 'F1_gene': 0.41909188664192304, 'val_accuracy': 0.28052243043725156, 'val_F1_gene': 0.4352993611647601, 'loss': 0.8734314143657684, 'accuracy': 0.26512791258940716, 'F1_other': 0.00011941011403665891, 'val_F1_other': 0.008865710560625815}\n",
      "3 {'val_loss': 0.7859598398208618, 'F1_gene': 0.41768645464427223, 'val_accuracy': 0.3333333333333333, 'val_F1_gene': 0.4308338720103426, 'loss': 0.8286062479019165, 'accuracy': 0.2712712273465268, 'F1_other': 0.026496277624714227, 'val_F1_other': 0.19552306989492918}\n",
      "4 {'val_loss': 0.7226979732513428, 'F1_gene': 0.005587510271158586, 'val_accuracy': 0.7219382926367595, 'val_F1_gene': 0.0, 'loss': 0.7703042328357697, 'accuracy': 0.7344771600333494, 'F1_other': 0.8467829741979591, 'val_F1_other': 0.8385181928108167}\n",
      "5 {'val_loss': 0.7297829389572144, 'F1_gene': 0.0, 'val_accuracy': 0.7221275790270679, 'val_F1_gene': 0.0, 'loss': 0.6966344118118286, 'accuracy': 0.7348720874105928, 'F1_other': 0.8471772561715905, 'val_F1_other': 0.8386458562321389}\n",
      "6 {'val_loss': 0.6497583985328674, 'F1_gene': 0.0, 'val_accuracy': 0.7221275790270679, 'val_F1_gene': 0.0, 'loss': 0.6059285998344421, 'accuracy': 0.7348720874105928, 'F1_other': 0.8471772561715905, 'val_F1_other': 0.8386458562321389}\n",
      "7 {'val_loss': 0.6613461375236511, 'F1_gene': 0.0, 'val_accuracy': 0.7221275790270679, 'val_F1_gene': 0.0, 'loss': 0.5365104079246521, 'accuracy': 0.7348720874105928, 'F1_other': 0.8471772561715905, 'val_F1_other': 0.8386458562321389}\n",
      "8 {'val_loss': 0.6156384348869324, 'F1_gene': 0.0, 'val_accuracy': 0.7221275790270679, 'val_F1_gene': 0.0, 'loss': 0.5116450786590576, 'accuracy': 0.7348720874105928, 'F1_other': 0.8471772561715905, 'val_F1_other': 0.8386458562321389}\n",
      "9 {'val_loss': 0.6098452806472778, 'F1_gene': 0.0, 'val_accuracy': 0.7221275790270679, 'val_F1_gene': 0.0, 'loss': 0.46792013943195343, 'accuracy': 0.7348720874105928, 'F1_other': 0.8471772561715905, 'val_F1_other': 0.8386458562321389}\n",
      "10 {'val_loss': 0.599642813205719, 'F1_gene': 0.0, 'val_accuracy': 0.7221275790270679, 'val_F1_gene': 0.0, 'loss': 0.4452463388442993, 'accuracy': 0.7348720874105928, 'F1_other': 0.8471772561715905, 'val_F1_other': 0.8386458562321389}\n",
      "11 {'val_loss': 0.5964652299880981, 'F1_gene': 0.0, 'val_accuracy': 0.7221275790270679, 'val_F1_gene': 0.0, 'loss': 0.423796683549881, 'accuracy': 0.7348720874105928, 'F1_other': 0.8471772561715905, 'val_F1_other': 0.8386458562321389}\n",
      "12 {'val_loss': 0.6057734489440918, 'F1_gene': 0.0, 'val_accuracy': 0.7221275790270679, 'val_F1_gene': 0.0, 'loss': 0.40461333096027374, 'accuracy': 0.7348720874105928, 'F1_other': 0.8471772561715905, 'val_F1_other': 0.8386458562321389}\n",
      "13 {'val_loss': 0.6045477390289307, 'F1_gene': 0.0, 'val_accuracy': 0.7221275790270679, 'val_F1_gene': 0.0, 'loss': 0.3876332640647888, 'accuracy': 0.7348720874105928, 'F1_other': 0.8471772561715905, 'val_F1_other': 0.8386458562321389}\n",
      "14 {'val_loss': 0.6020429730415344, 'F1_gene': 0.00033096144299189144, 'val_accuracy': 0.7221275790270679, 'val_F1_gene': 0.0, 'loss': 0.3711683601140976, 'accuracy': 0.7349159682302865, 'F1_other': 0.8471986847097509, 'val_F1_other': 0.8386458562321389}\n",
      "15 {'val_loss': 0.5980104207992554, 'F1_gene': 0.00033096144299189144, 'val_accuracy': 0.7221275790270679, 'val_F1_gene': 0.0, 'loss': 0.3553299903869629, 'accuracy': 0.7349159682302865, 'F1_other': 0.8471986847097509, 'val_F1_other': 0.8386458562321389}\n",
      "16 {'val_loss': 0.5960437655448914, 'F1_gene': 0.00033096144299189144, 'val_accuracy': 0.7221275790270679, 'val_F1_gene': 0.0, 'loss': 0.33815625309944153, 'accuracy': 0.7349159682302865, 'F1_other': 0.8471986847097509, 'val_F1_other': 0.8386458562321389}\n",
      "17 {'val_loss': 0.5894399881362915, 'F1_gene': 0.0006618133686300463, 'val_accuracy': 0.7221275790270679, 'val_F1_gene': 0.0, 'loss': 0.3220820873975754, 'accuracy': 0.7349598490499802, 'F1_other': 0.8472201143319674, 'val_F1_other': 0.8386458562321389}\n",
      "18 {'val_loss': 0.5832040309906006, 'F1_gene': 0.0009925558312655087, 'val_accuracy': 0.7221275790270679, 'val_F1_gene': 0.0, 'loss': 0.306017741560936, 'accuracy': 0.735003729869674, 'F1_other': 0.8472415450383224, 'val_F1_other': 0.8386458562321389}\n",
      "19 {'val_loss': 0.5808404684066772, 'F1_gene': 0.0016534391534391533, 'val_accuracy': 0.7221275790270679, 'val_F1_gene': 0.0, 'loss': 0.2909630239009857, 'accuracy': 0.7350476106893676, 'F1_other': 0.8472552491778396, 'val_F1_other': 0.8386458562321389}\n",
      "20 {'val_loss': 0.5692621469497681, 'F1_gene': 0.001983798975037196, 'val_accuracy': 0.7221275790270679, 'val_F1_gene': 0.0, 'loss': 0.2762390226125717, 'accuracy': 0.7350914915090614, 'F1_other': 0.8472766829416378, 'val_F1_other': 0.8386458562321389}\n",
      "21 {'val_loss': 0.5633355975151062, 'F1_gene': 0.003303600925008259, 'val_accuracy': 0.7221275790270679, 'val_F1_gene': 0.0, 'loss': 0.2620146721601486, 'accuracy': 0.7352231339681425, 'F1_other': 0.847333265863779, 'val_F1_other': 0.8386458562321389}\n",
      "22 {'val_loss': 0.5601648092269897, 'F1_gene': 0.032216075496257726, 'val_accuracy': 0.7228847245883021, 'val_F1_gene': 0.010810810810810811, 'loss': 0.24791263788938522, 'accuracy': 0.7389968844618018, 'F1_other': 0.8491580442280381, 'val_F1_other': 0.8388729914153643}\n",
      "23 {'val_loss': 0.5524615049362183, 'F1_gene': 0.3035888842340455, 'val_accuracy': 0.7340526216165058, 'val_F1_gene': 0.15412402167369055, 'loss': 0.23421671241521835, 'accuracy': 0.7811663521874589, 'F1_other': 0.8701876773303485, 'val_F1_other': 0.8422234699606962}\n",
      "24 {'val_loss': 0.5541446208953857, 'F1_gene': 0.6962471934138779, 'val_accuracy': 0.740488358886996, 'val_F1_gene': 0.21070811744386875, 'loss': 0.22132416814565659, 'accuracy': 0.8753345912501646, 'F1_other': 0.9215734989648033, 'val_F1_other': 0.8447162759089365}\n",
      "25 {'val_loss': 0.5541890263557434, 'F1_gene': 0.8222350897510133, 'val_accuracy': 0.7266704523944728, 'val_F1_gene': 0.23839662447257384, 'loss': 0.2086537927389145, 'accuracy': 0.9191715301241827, 'F1_other': 0.947694229895502, 'val_F1_other': 0.8334486735870819}\n",
      "26 {'val_loss': 0.5556778311729431, 'F1_gene': 0.8907350550839805, 'val_accuracy': 0.7151239825856521, 'val_F1_gene': 0.2553191489361702, 'loss': 0.19713297486305237, 'accuracy': 0.9469042081706086, 'F1_other': 0.964931602133086, 'val_F1_other': 0.8238736102984201}\n",
      "27 {'val_loss': 0.5659528970718384, 'F1_gene': 0.9189094107299912, 'val_accuracy': 0.7058489494605338, 'val_F1_gene': 0.21594349142280525, 'loss': 0.18638121336698532, 'accuracy': 0.9595418842423976, 'F1_other': 0.9730472404115996, 'val_F1_other': 0.8189655172413793}\n",
      "28 {'val_loss': 0.5896865129470825, 'F1_gene': 0.9273344356452876, 'val_accuracy': 0.6965739163354154, 'val_F1_gene': 0.18505338078291814, 'loss': 0.17576253414154053, 'accuracy': 0.9633595155557506, 'F1_other': 0.9755038577756916, 'val_F1_other': 0.8135829747645075}\n",
      "29 {'val_loss': 0.5850016474723816, 'F1_gene': 0.9405433111225013, 'val_accuracy': 0.6954381979935642, 'val_F1_gene': 0.19590204897551225, 'loss': 0.1656958907842636, 'accuracy': 0.9694589494931766, 'F1_other': 0.9794520547945206, 'val_F1_other': 0.8121424401634559}\n",
      "30 {'val_loss': 0.594929575920105, 'F1_gene': 0.9445341034570628, 'val_accuracy': 0.6935453340904789, 'val_F1_gene': 0.18438287153652394, 'loss': 0.1559598594903946, 'accuracy': 0.9713458247400062, 'F1_other': 0.9806833308682148, 'val_F1_other': 0.8113273511245775}\n",
      "31 {'val_loss': 0.5985590815544128, 'F1_gene': 0.9540268456375839, 'val_accuracy': 0.6950596252129472, 'val_F1_gene': 0.20128904313336637, 'loss': 0.1469091773033142, 'accuracy': 0.9759533108078459, 'F1_other': 0.9837185810208569, 'val_F1_other': 0.8115569072406129}\n",
      "32 {'val_loss': 0.6129529476165771, 'F1_gene': 0.9604133677806483, 'val_accuracy': 0.6961953435547984, 'val_F1_gene': 0.2113022113022113, 'loss': 0.1383572816848755, 'accuracy': 0.9791566106454869, 'F1_other': 0.9858542541469371, 'val_F1_other': 0.8118626186847966}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 {'val_loss': 0.6177104711532593, 'F1_gene': 0.9616858237547893, 'val_accuracy': 0.6910846110164679, 'val_F1_gene': 0.20390243902439023, 'loss': 0.1301436424255371, 'accuracy': 0.9798148229408925, 'F1_other': 0.9862981055641606, 'val_F1_other': 0.8083607327383748}\n",
      "34 {'val_loss': 0.6237592101097107, 'F1_gene': 0.9694315928618639, 'val_accuracy': 0.6891917471133826, 'val_F1_gene': 0.19667318982387474, 'loss': 0.1213526539504528, 'accuracy': 0.9837640967133267, 'F1_other': 0.9889466451574356, 'val_F1_other': 0.8073222248298522}\n",
      "35 {'val_loss': 0.6436880826950073, 'F1_gene': 0.9705226653455536, 'val_accuracy': 0.6855953056975204, 'val_F1_gene': 0.1707438841737394, 'loss': 0.11356929317116737, 'accuracy': 0.9843345473693449, 'F1_other': 0.9893327755699645, 'val_F1_other': 0.8060259254934018}\n",
      "36 {'val_loss': 0.640314519405365, 'F1_gene': 0.972330056991823, 'val_accuracy': 0.6810524323301155, 'val_F1_gene': 0.16210840377921432, 'loss': 0.10644577443599701, 'accuracy': 0.9852999254026065, 'F1_other': 0.9899913357832153, 'val_F1_other': 0.8030391583869082}\n",
      "37 {'val_loss': 0.6340161561965942, 'F1_gene': 0.970374048328368, 'val_accuracy': 0.6753738406208594, 'val_F1_gene': 0.14378432351472792, 'loss': 0.09965440630912781, 'accuracy': 0.9842906665496511, 'F1_other': 0.9893115184809219, 'val_F1_other': 0.7997197243956558}\n",
      "38 {'val_loss': 0.625275731086731, 'F1_gene': 0.9715276058430304, 'val_accuracy': 0.6818095778913497, 'val_F1_gene': 0.20066571564431765, 'loss': 0.09321798384189606, 'accuracy': 0.9848611172056694, 'F1_other': 0.989689489256149, 'val_F1_other': 0.8013706723384143}\n",
      "39 {'val_loss': 0.6370609402656555, 'F1_gene': 0.9672703106828376, 'val_accuracy': 0.6814310051107325, 'val_F1_gene': 0.18498789346246974, 'loss': 0.09005212783813477, 'accuracy': 0.9827109570406776, 'F1_other': 0.988252832438879, 'val_F1_other': 0.802023291377485}\n",
      "40 {'val_loss': 0.6316278576850891, 'F1_gene': 0.9739502013312515, 'val_accuracy': 0.6814310051107325, 'val_F1_gene': 0.21974965229485396, 'loss': 0.08399126306176186, 'accuracy': 0.9860897801570934, 'F1_other': 0.9905115388069083, 'val_F1_other': 0.7998572957545487}\n",
      "41 {'val_loss': 0.6328012943267822, 'F1_gene': 0.9728350345735923, 'val_accuracy': 0.6910846110164679, 'val_F1_gene': 0.24723247232472326, 'loss': 0.07895351573824883, 'accuracy': 0.9855193295010751, 'F1_other': 0.990128626981753, 'val_F1_other': 0.805668016194332}\n",
      "42 {'val_loss': 0.6301929950714111, 'F1_gene': 0.9706732755059893, 'val_accuracy': 0.6994132121900435, 'val_F1_gene': 0.26820276497695855, 'loss': 0.07226994261145592, 'accuracy': 0.9844223090087323, 'F1_other': 0.9893944373076808, 'val_F1_other': 0.8108623153882801}\n",
      "43 {'val_loss': 0.611325204372406, 'F1_gene': 0.9719133514537518, 'val_accuracy': 0.6958167707741814, 'val_F1_gene': 0.29855958096900914, 'loss': 0.06720920279622078, 'accuracy': 0.9850366404844443, 'F1_other': 0.9898017166611838, 'val_F1_other': 0.8058006042296072}\n",
      "44 {'val_loss': 0.614252507686615, 'F1_gene': 0.9729504090833194, 'val_accuracy': 0.7043346583380655, 'val_F1_gene': 0.3214596003475239, 'loss': 0.06325962394475937, 'accuracy': 0.9857826144192373, 'F1_other': 0.9903571428571428, 'val_F1_other': 0.8109874152952565}\n",
      "45 {'val_loss': 0.6071221232414246, 'F1_gene': 0.9725644816822737, 'val_accuracy': 0.7052810902896082, 'val_F1_gene': 0.3256821134690342, 'loss': 0.05928972736001015, 'accuracy': 0.9853438062223002, 'F1_other': 0.9900011974613818, 'val_F1_other': 0.8114327237495459}\n",
      "46 {'val_loss': 0.6590814590454102, 'F1_gene': 0.9762235476754637, 'val_accuracy': 0.6854060193072118, 'val_F1_gene': 0.23126734505087881, 'loss': 0.05573967099189758, 'accuracy': 0.9872306814691298, 'F1_other': 0.9912714838477459, 'val_F1_other': 0.8022370299857211}\n",
      "47 {'val_loss': 0.7224305272102356, 'F1_gene': 0.9725148123765636, 'val_accuracy': 0.676320272572402, 'val_F1_gene': 0.1551383399209486, 'loss': 0.05187954753637314, 'accuracy': 0.9853438062223002, 'F1_other': 0.9900077783761144, 'val_F1_other': 0.7998126902364786}\n",
      "48 {'val_loss': 0.722865641117096, 'F1_gene': 0.9683078196110881, 'val_accuracy': 0.6825667234525837, 'val_F1_gene': 0.18473505104521148, 'loss': 0.047663845121860504, 'accuracy': 0.9831936460573083, 'F1_other': 0.9885647747290479, 'val_F1_other': 0.8029145610530027}\n",
      "49 {'val_loss': 0.7400746941566467, 'F1_gene': 0.9713158543601546, 'val_accuracy': 0.6462237365133446, 'val_F1_gene': 0.002135611318739989, 'loss': 0.043360352516174316, 'accuracy': 0.9846855939268946, 'F1_other': 0.9895543383915477, 'val_F1_other': 0.7849994248245715}\n",
      "50 {'val_loss': 0.7025020718574524, 'F1_gene': 0.9739144656145229, 'val_accuracy': 0.6867310240393716, 'val_F1_gene': 0.15776081424936386, 'loss': 0.04047741740942001, 'accuracy': 0.9860020185177059, 'F1_other': 0.9904344957869802, 'val_F1_other': 0.8075805138937333}\n",
      "51 {'val_loss': 0.7150974869728088, 'F1_gene': 0.9716352873468717, 'val_accuracy': 0.6871095968199886, 'val_F1_gene': 0.1893084845512506, 'loss': 0.036209847778081894, 'accuracy': 0.9848611172056694, 'F1_other': 0.9896752955259613, 'val_F1_other': 0.8061451858801454}\n",
      "52 {'val_loss': 0.6928250789642334, 'F1_gene': 0.9741951339395429, 'val_accuracy': 0.689002460723074, 'val_F1_gene': 0.23116518483855872, 'loss': 0.032557256519794464, 'accuracy': 0.9861775417964808, 'F1_other': 0.990560666446915, 'val_F1_other': 0.8050777079131569}\n",
      "53 {'val_loss': 0.6818264722824097, 'F1_gene': 0.9751121991024072, 'val_accuracy': 0.6920310429680105, 'val_F1_gene': 0.2553775743707094, 'loss': 0.028517626225948334, 'accuracy': 0.9866163499934179, 'F1_other': 0.9908471626204123, 'val_F1_other': 0.8058704211907887}\n",
      "54 {'val_loss': 0.688199520111084, 'F1_gene': 0.9757333115450608, 'val_accuracy': 0.6933560477001703, 'val_F1_gene': 0.24581005586592178, 'loss': 0.02510708197951317, 'accuracy': 0.9869673965509675, 'F1_other': 0.9910915144425447, 'val_F1_other': 0.8075552387740556}\n",
      "55 {'val_loss': 0.6867321133613586, 'F1_gene': 0.9766565648292244, 'val_accuracy': 0.7035775127768313, 'val_F1_gene': 0.2926829268292683, 'loss': 0.02249901369214058, 'accuracy': 0.9874939663872921, 'F1_other': 0.9914591387215679, 'val_F1_other': 0.8125}\n"
     ]
    }
   ],
   "source": [
    "from sequence_annotation.process.ann_seq_data import AnnSeqData\n",
    "from sequence_annotation.pytorch.worker import Trainer\n",
    "from sequence_annotation.process.pipeline import Pipeline \n",
    "from sequence_annotation.function.model_processor import SimpleModel\n",
    "from sequence_annotation.pytorch.compiler import SimpleCompiler\n",
    "import torch.optim as optim\n",
    "from sequence_annotation.pytorch.customize_layer import FocalLoss\n",
    "from sequence_annotation.pytorch.callback import CategoricalMetric,TensorboardCallback,TensorboardWriter,SeqFigCallback\n",
    "from tensorboardX import SummaryWriter\n",
    "import shutil\n",
    "#shutil.rmtree('../io/record/train_2019_02_16_model_3_lr_3', ignore_errors=True)\n",
    "writer = TensorboardWriter(SummaryWriter('../io/record/train_2019_02_16_model_5_rnn_zero_center'))\n",
    "\n",
    "loss = SeqAnnlLoss(class_num=class_num,ignore_index=-1,gamma=0).cuda()\n",
    "builder = SimpleModel(model)\n",
    "compiler = SimpleCompiler(lambda params:optim.Adam(params,lr=0.01),loss)\n",
    "data = AnnSeqData({'training':{'inputs':selected_fasta,'answers':selected_seqs}},\n",
    "                   discard_invalid_seq=True,validation_split=0.1)\n",
    "train_metric = CategoricalMetric(class_num=class_num,ignore_index=-1,class_names=selected_seqs.ANN_TYPES)\n",
    "val_metric = CategoricalMetric(prefix='val',class_num=class_num,ignore_index=-1,class_names=selected_seqs.ANN_TYPES)\n",
    "tensorboard = TensorboardCallback(writer)\n",
    "seq = SeqConverter().seq2vecs(fasta[outlier_name])\n",
    "seq = np.transpose(np.array([seq]),[0,2,1])\n",
    "seq = torch.from_numpy(seq).type('torch.FloatTensor').cuda()\n",
    "seq_fig = SeqFigCallback(writer,seq,class_names=selected_seqs.ANN_TYPES,colors=['blue','red'],prefix='test')\n",
    "worker = Trainer(batch_size=16,return_extra_info=True, order='NCL', order_target=['answers','inputs'],\n",
    "                 pad_value={'answers':-1,'inputs':0},epoch_num=100,generator=SeqGenerator,\n",
    "                 train_callbacks=[train_metric],val_callbacks=[val_metric],other_callbacks=[tensorboard,seq_fig],\n",
    "                writer=writer)\n",
    "pipeline = Pipeline(builder,data,worker,compiler,\n",
    "                    is_prompt_visible=True)\n",
    "pipeline.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "visual_ann_seq(ann_seqs.get(outlier_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.2392], device='cuda:0')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noisy_relu(c=0.5)(torch.FloatTensor([-100000000000]).cuda(),True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
